<!DOCTYPE html>
<html lang="zh-CN">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="TDA4开发" />
    <meta name="hexo-theme-A4" content="v1.9.8" />
    <link rel="alternate icon" type="image/webp" href="/img/20250602032635.jpg">
    <title>Yann | 我愿做你光华中淡淡的一笔</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--注意：首页既不是post也不是page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--返回顶部css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--目录-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


   
        
<link rel="stylesheet" href="/css/custom.css">

    

<meta name="generator" content="Hexo 5.4.2"></head>
    
    

    
    



    

    
    




    
    <style>
        :root {
            --waline-theme-color: #323e74; 
            --waline-color: #323e74; 
            --waline-border-color: #323e74; 
            --waline-white: #323e74; 
            --waline-bgcolor-light: #f2fafc;  
        }
        body {
            color: #323e74;
            background: #eaeae8;
        }
        .post-md code {
            background: #e7f7f3;
            color: #7f688d; 
        }
        .post-md pre, .post-md .highlight {
            background: #e7f7f3;
            color: #7f688d; 
        }
        pre .string, pre .value, pre .inheritance, pre .header, pre .ruby .symbol, pre .xml .cdata {
            color: #323e74;
        }
        pre .number, pre .preprocessor, pre .built_in, pre .literal, pre .params, pre .constant {
            color: #323e74;
        }
        .year-font-color {
            color: #323e74 !important;
        }
        .wl-card span.wl-nick {
            color: #323e74; 
        }
        .wl-card .wl-badge {
            border: 1px solid #323e74;
            color: #323e74; 
        }
        .wl-btn {
            border: 1px solid #323e74; 
            color:  #323e74;  
        }
        .wl-btn.primary {
            color: #f2fafc; 
        }
        .wl-header label {
            color: #323e74;
        }
        a {
            color: #7f688d;
        }

        .post-md a {
            color: #7f688d;
        }

        .nav li a {
            color: #7f688d;
        }

        .archive-main a:link {
            color: #7f688d;
        }
        .archive-main a:visited {
            color: #767c7c; 
        }

        .archive li span {
            color: #323e74;
        }

        .post-main-title {
            color: #323e74;
        }

        .post-md h1,
        .post-md h2,
        .post-md h3,
        .post-md h4,
        .post-md h5,
        .post-md h6 {
            color: #323e74;
        }

        [data-waline] p {
            color: #323e74;
        }
        [data-waline] a {
            color: #323e74;
        } 
        .wl-sort li.active {
            color: #323e74;
        }

        .wl-card .wl-meta>span {
            background: #f2fafc;
        }

        .paper {
            background: #eaeae8;
        }

        .index-main {
            background: #f2fafc;
        }

        .paper-main {
            background: #f2fafc;
        }

        .wl-panel {
            background: #f2fafc;
        }

        .archive li:nth-child(odd) {
            background: #f2fafc;
            ;
        }

        .archive li:nth-child(even) {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(odd) td {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(even) td {
            background: #f2fafc;
        }

    
        .progress-wrap::after {
            color: #323e74; /* 箭头的颜色 */
        }
        .progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* 边框的颜色 */
        }
        .progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* 鼠标滑过的箭头颜色 */
         }

        .return-to-last-progress-wrap::after {
            color: #323e74; /* 箭头的颜色 */
        }
        .return-to-last-progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* 边框的颜色 */
        }
        .return-to-last-progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* 鼠标滑过的箭头颜色 */
         }

         .left-toc-container::-webkit-scrollbar-thumb {
            background-color: #323e74; /* 设置滚动条拖动块的颜色 */
        }

        .bs-docs-sidebar .nav>.active>a,
        .bs-docs-sidebar .nav>li>a:hover,
        .bs-docs-sidebar .nav>li>a:focus {
            color: #7f688d;
            border-left-color: #7f688d;
        }
        .bs-docs-sidebar .nav>li>a {
            color:  #323e74;
        }
    </style>

    
    <style>
        body {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* 背景固定，不随页面滚动 */
            background-repeat: no-repeat;  /* 防止背景图片重复 */
            background-size: cover;       /* 背景自适应大小，覆盖整个背景 */
            background-position: center;   /* 背景居中显示 */
        }
        .paper {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* 背景固定，不随页面滚动 */
            background-repeat: no-repeat;  /* 防止背景图片重复 */
            background-size: cover;       /* 背景自适应大小，覆盖整个背景 */
            background-position: center;   /* 背景居中显示 */
        }  
    </style>


    
    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        <script>
            const options = {
                bottom: '40px', // default: '32px'
                right: 'unset', // default: '32px'
                left: '42px', // default: 'unset'
                time: '0.3s', // default: '0.3s'
                mixColor: '#fff', // default: '#fff'
                backgroundColor: ' #eaeae8  ',  // default: '#fff'
                buttonColorDark: '#100f2c',  // default: '#100f2c'
                buttonColorLight: '#fff', // default: '#fff'
                saveInCookies: true, // default: true,
                label: '🌓', // default: ''
                autoMatchOsTheme: true // default: true
            }
            const darkmode = new Darkmode(options);
            darkmode.showWidget();
        </script>
        
        
            
                <div class="left-toc-container">
                    <nav id="toc" class="bs-docs-sidebar"></nav>
                </div>
            
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <style>
            .header-img {
                width: 56px;
                height: auto;
                object-fit: cover; /* 保持图片比例 */
                transition: transform 0.3s ease-in-out; 
                border-radius: 0; 
            }
            
        </style>
        <img 
            alt="^-^" 
            cache-control="max-age=86400" 
            class="header-img" 
            src="/img/20250602032635.jpg" 
        />
        <div class="header-content">
            <a class="logo" href="/">Yann</a> 
            <span class="description">人工智能、计算机、机器学习、linux、程序员</span> 
        </div>
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">文章</a></li>
            
        
            
                <li><a href="/about/">关于</a></li>
            
        
            
                <li><a href="/tags/">标签</a></li>
            
        
            
                <li><a href="/categories/">分类</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    TDA4开发
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>最近更新：2022-07-24</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>字数总计：3.2k</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>阅读估时：13分钟</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        阅读量：<span id="busuanzi_value_page_pv"></span>次
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#TDA4%E5%BC%80%E5%8F%91-%E4%B8%80-soc%E4%BB%8B%E7%BB%8D"><span class="post-toc-text">TDA4开发(一) soc介绍</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Preface"><span class="post-toc-text">Preface</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#TDA4VM-SK"><span class="post-toc-text">TDA4VM SK</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%94%AF%E6%8C%81%E7%9A%84%E7%9B%B8%E6%9C%BA%E8%BE%93%E5%85%A5"><span class="post-toc-text">支持的相机输入</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BD%AF%E4%BB%B6%E8%AE%BE%E7%BD%AE"><span class="post-toc-text">软件设置</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#References"><span class="post-toc-text">References</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#TDA4%E5%BC%80%E5%8F%91-%E4%BA%8C-%E8%BF%90%E8%A1%8Cdemo"><span class="post-toc-text">TDA4开发(二) 运行demo</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%90%E8%A1%8C%E6%9D%BF%E8%BD%BDdemo"><span class="post-toc-text">运行板载demo</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="post-toc-text">配置文件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Inputs"><span class="post-toc-text">Inputs</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Models"><span class="post-toc-text">Models</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Outputs"><span class="post-toc-text">Outputs</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Flows"><span class="post-toc-text">Flows</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD"><span class="post-toc-text">模型下载</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="post-toc-text">自定义模型</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#References-1"><span class="post-toc-text">References</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#TDA4%E5%BC%80%E5%8F%91-%E4%B8%89-%E8%BF%90%E8%A1%8Cdemo"><span class="post-toc-text">TDA4开发(三) 运行demo</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#TiDL-tools"><span class="post-toc-text">TiDL-tools</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#WorkFlow"><span class="post-toc-text">WorkFlow</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="post-toc-text">模型转换</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1%EF%BC%8C%E5%9C%A8PC%E4%B8%8A%E6%90%AD%E5%BB%BA%E7%8E%AF%E5%A2%83-3"><span class="post-toc-text">1，在PC上搭建环境[3]</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2%EF%BC%8C%E9%AA%8C%E8%AF%81%E7%8E%AF%E5%A2%83%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8"><span class="post-toc-text">2，验证环境是否可用</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3%EF%BC%8CSOC%E7%AB%AF%E6%8E%A8%E7%90%86"><span class="post-toc-text">3，SOC端推理</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#References-2"><span class="post-toc-text">References</span></a></li></ol></li></ol>
            
        
        <div class=".article-gallery"><blockquote>
<p>TI 的 TDA4VM SoC 包含双核 A72、高性能视觉加速器、视频编解码器加速器、最新的 C71x 和 C66x DSP、用于捕获和显示的高带宽实时 IP、GPU、专用安全岛和安全加速器。SoC 经过功率优化，可为机器人、工业和汽车应用中的感知、传感器融合、定位和路径规划任务提供一流的性能。TDA4VM Edge AI Starter Kit (SK) 是一款低成本、小尺寸板，功耗大约20W，能提供8TOPS深度学习算力，支持Tensorflow Lite,ONNX,TVM,GStreamer接口</p>
</blockquote>
<span id="more"></span>
<h2 id="TDA4开发-一-soc介绍"><a href="#TDA4开发-一-soc介绍" class="headerlink" title="TDA4开发(一) soc介绍"></a>TDA4开发(一) soc介绍</h2><h3 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h3><p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724211613695.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724211613695.png" alt=""></a></p>
<h3 id="TDA4VM-SK"><a href="#TDA4VM-SK" class="headerlink" title="TDA4VM SK"></a>TDA4VM SK</h3><p><strong>运行前准备</strong></p>
<p>•SK板</p>
<p>•USB camera  •支持HDMI或者DP口的显示器  •至少16GB空间SD卡，如果大于16G，需要手动拓展 root filesystem</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212422704.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212422704.png" alt=""></a></p>
<p>•网线和局域网  </p>
<p>•串口电源（5-20V DC），功率保证20W以上  如果功率不够，运行期间可能导致重启</p>
<p><strong>设置启动模式</strong></p>
<p>将拨码开关拨到如图所示位置，系统从SD卡启动</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212522518.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212522518.png" alt=""></a></p>
<h3 id="支持的相机输入"><a href="#支持的相机输入" class="headerlink" title="支持的相机输入"></a>支持的相机输入</h3><p><strong>USB Camera</strong></p>
<p>驱动已经在SDK中解决了，根据文档说明，已经测试过C270/C920/C922三款camera，如果遇到camera打不开的情况参考文档[1]</p>
<p><strong>YUV sensor</strong></p>
<p>支持OV5640，200万像素，CSI接口，YUYV输出，产品信息[2]默认在SDK中，OV5640是被屏蔽的，需要手动开启支持打开<code>/run/media/mmcblk0p1/uenv.txt</code></p>
<p>然后编辑</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name_overlays=k3-j721e-edgeai-apps.dtbo k3-j721e-sk-csi2-ov5640.dtbo</span><br></pre></td></tr></table></figure>
<p>重启设备即可</p>
<p><strong>Raw sensor</strong></p>
<p>RPiV2</p>
<h3 id="软件设置"><a href="#软件设置" class="headerlink" title="软件设置"></a>软件设置</h3><p>下载SDK包[3]</p>
<p>下载烧录软件[4]</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212600518.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212600518.png" alt=""></a></p>
<p>烧录软件使用1.7.0版本烧录完成即可上电启动</p>
<p>先插入SD卡，然后再上电，显示器就会有如下图所示画面，代表启动成功</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212621593.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212621593.png" alt=""></a></p>
<p>板子默认在串口打印日志，所以初次上电需要连接串口，登陆账号</p>
<p><strong>串口使用</strong></p>
<p>在host ubuntu上推荐安装minicom，minicom使用方法参考[5]</p>
<p>在windows上推荐安装teraterm[6]</p>
<p>ubuntu下启动minicom</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo minicom -D /dev/ttyUSB2 -c on</span><br></pre></td></tr></table></figure>
<p>板子默认串口波特率是115200 连接串口登陆用户名是root，不需要密码进去之后，ifconfig查询板子ip地址，后面即可使用ssh登陆</p>
<p>推荐使用vscode，可以利用remote插件来直接ssh登陆到板子，然后可以很方便地修改配置文件</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212646622.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724212646622.png" alt=""></a></p>
<p><strong>配置软件环境</strong></p>
<p>软件环境配置才是重点，例如安装tensorflow，onnx，python和c++依赖库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/edge_ai_apps#./setup_script.sh</span><br></pre></td></tr></table></figure>
<p>运行上面脚本，所有环境自动安装</p>
<p>•clone Tensoflow•clone ONNX-RT•clone edgeai-tiovx-modules•clone edgai-gst-plugins•clone adgeai-tidl-tools•compile C++ apps</p>
<p>经常会遇到运行失败，原因就是访问github比较慢，多试几次就好</p>
<p>如果需要调试相关环境，直接在运行的时候，加入参数，即可编译debug版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@j7-evm:/opt/edge_ai_apps#./setup_script.sh -d</span><br></pre></td></tr></table></figure>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p><code>[1]</code> 参考文档: <em><a target="_blank" rel="noopener" href="https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/faq.html#pub-edgeai-multiple-usb-cams">https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/faq.html#pub-edgeai-multiple-usb-cams</a></em><br><code>[2]</code> 产品信息: <em><a target="_blank" rel="noopener" href="https://www.leopardimaging.com/product/cmos-sensor-modules/mipi-camera-modules/li-am65x-csi2">https://www.leopardimaging.com/product/cmos-sensor-modules/mipi-camera-modules/li-am65x-csi2</a></em><br><code>[3]</code> SDK包: <em><a target="_blank" rel="noopener" href="https://dr-download.ti.com/software-development/software-development-kit-sdk/MD-4K6R4tqhZI/08.02.00.02/ti-processor-sdk-linux-sk-tda4vm-etcher-image.zip">https://dr-download.ti.com/software-development/software-development-kit-sdk/MD-4K6R4tqhZI/08.02.00.02/ti-processor-sdk-linux-sk-tda4vm-etcher-image.zip</a></em><br><code>[4]</code> 烧录软件: <em><a target="_blank" rel="noopener" href="https://github.com/balena-io/etcher/releases/tag/v1.7.0">https://github.com/balena-io/etcher/releases/tag/v1.7.0</a></em><br><code>[5]</code> minicom使用方法参考: <em><a target="_blank" rel="noopener" href="https://help.ubuntu.com/community/Minicom">https://help.ubuntu.com/community/Minicom</a></em><br><code>[6]</code> teraterm: <em><a target="_blank" rel="noopener" href="https://learn.sparkfun.com/tutorials/terminal-basics/tera-term-windows">https://learn.sparkfun.com/tutorials/terminal-basics/tera-term-windows</a></em></p>
<h1 id="TDA4开发-二-运行demo"><a href="#TDA4开发-二-运行demo" class="headerlink" title="TDA4开发(二) 运行demo"></a>TDA4开发(二) 运行demo</h1><p>原创 carpenter 卡本特 <em>2022-07-08 20:30</em> <em>发表于广东</em></p>
<p>收录于合集#Ti-tda44个</p>
<h3 id="运行板载demo"><a href="#运行板载demo" class="headerlink" title="运行板载demo"></a>运行板载demo</h3><p>Ti在板载端提供了非常丰富的demo，每个demo都提供了输入文件，模型文件。只需要修改config文件运行即可，demo分为python版本和c++版本，C++版本的运行效率会稍微高一些</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>配置文件通过使用YAML格式来设置参数，配置文件路径为<code>edge_ai_app/configs</code></p>
<p>在配置文件中指定了demo运行的输入类型，例如picture, video, camera</p>
<p>还可以指定加载模型的路径，指定输出类型，例如是保存到本地文件还是输出到显示器</p>
<p>如下图所示</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213111606.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213111606.png" alt=""></a></p>
<p>config 文件分为四个部分</p>
<p>•Inputs</p>
<p>•Models</p>
<p>•Outputs</p>
<p>•Flows</p>
<h3 id="Inputs"><a href="#Inputs" class="headerlink" title="Inputs"></a><strong>Inputs</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs:    input0:                                         #Camera Input        source: /dev/video2                         #Device file entry of the camera        format: jpeg                                #Input data format suported by camera        width: 1280                                 #Width and Height of the input        height: 720        framerate: 30                               #Framerate of the source</span><br><span class="line">    input1:                                         #Video Input        source: ../data/videos/video_0000_h264.mp4  #Video file        format: h264                                #File encoding format        width: 1280        height: 720        framerate: 25</span><br><span class="line">    input2:                                         #Image Input        source: ../data/images/%04d.jpg             #Sequence of Image files, printf style formatting is used        width: 1280        height: 720        index: 0                                    #Starting Index (optional)</span><br></pre></td></tr></table></figure>
<p><strong>1, Camera</strong></p>
<p>挂载到板子上的camera会被v4l2src GStreamer来作解析，是否会被识别为camera，需要使用脚本来验证</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./init_script.sh</span><br></pre></td></tr></table></figure>
<p>如果插上的camera能够成功被识别，那么会有如下输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@j7-evm:/opt/edge_ai_apps# ./init_script.shUSB Camera detected    device = /dev/video2    format = jpeg</span><br></pre></td></tr></table></figure>
<p><strong>2, Video</strong></p>
<p>支持H264和H265格式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input1:    source: ../data/videos/video_0000_h264.mp4    format: h264    width: 1280    height: 720    framerate: 25</span><br><span class="line">input2:    source: ../data/videos/video_0000_h265.mp4    format: h265    width: 1280    height: 720    framerate: 25</span><br></pre></td></tr></table></figure>
<p>如果不确定某个视频文件具体的视频流格式，那么可以在<code>format</code>设置为<code>auto</code>, 可以被Gstreamer自动解码识别</p>
<p><strong>3, Images</strong></p>
<p>可以配置输入为多张图片，指定图片文件夹路径即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input2:    source: ../data/images/%04d.jpg    width: 1280    height: 720    index: 0    framerate: 1</span><br></pre></td></tr></table></figure>
<p><strong>4, RTSP stream</strong></p>
<p>GStreamer可以解析来自于RTSP数据源非加密数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input0:    source: rtsp://172.24.145.220:8554/test # rtsp stream url, replace this with correct url    width: 1280    height: 720    framerate: 30</span><br></pre></td></tr></table></figure>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a><strong>Models</strong></h3><p>配置推理模型的相关参数，包括模型路径，和模型参数，例如阈值。在anchor based的目标检测算法中可能有<code>topN</code>参数，在<code>segmentation</code>中有<code>alpha</code>参数, 不同类型的模型需要的配置参数不同</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">models:    model0:        model_path: ../models/segmentation/ONR-SS-871-deeplabv3lite-mobv2-cocoseg21-512x512   #Model Directory        alpha: 0.4                                                                            #alpha for blending segmentation mask (optional)    model1:        model_path: ../models/detection/TFL-OD-202-ssdLite-mobDet-DSP-coco-320x320        viz_threshold: 0.3                                                                    #Visualization threshold for adding bounding boxes (optional)    model2:        model_path: ../models/classification/TVM-CL-338-mobileNetV2-qat        topN: 5                                                                               #Number of top N classes (optional)</span><br></pre></td></tr></table></figure>
<h3 id="Outputs"><a href="#Outputs" class="headerlink" title="Outputs"></a><strong>Outputs</strong></h3><p>可以配置为显示器输出，保存为视频文件，输出为图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">outputs:    output0:                                                     #Display Output        sink: kmssink        width: 1920                                              #Width and Height of the output        height: 1080        connector: 39                                            #Connector ID for kmssink (optional)</span><br><span class="line">    output1:                                                     #Video Output        sink: ../data/output/videos/output_video.mkv             #Output video file        width: 1920        height: 1080</span><br><span class="line">    output2:                                                     #Image Output        sink: ../data/output/images/output_image_%04d.jpg        #Image file name, printf style formatting is used        width: 1920        height: 1080</span><br></pre></td></tr></table></figure>
<p><strong>1, 显示器输出</strong></p>
<p>支持DP和HDMI的输出，确认显示器是否成功连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@j7-evm:/opt/edge_ai_apps# modetest -M tidss -c | grep connected39      38      connected       DP-1            530x300         12      3848      0       disconnected    HDMI-A-1        0x0             0       47</span><br></pre></td></tr></table></figure>
<p>例如上面显示，connector 39是<code>connected</code>状态，所以在配置Output的时候，可以在<code>connector</code>填入39</p>
<p><strong>2，保存本地视频</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output1:    sink: ../data/output/videos/output_video.mkv    width: 1920    height: 1080</span><br></pre></td></tr></table></figure>
<p><strong>3，保存为图片</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output2:    sink: ../data/output/images/output_image_%04d.jpg    width: 1920    height: 1080</span><br></pre></td></tr></table></figure>
<h3 id="Flows"><a href="#Flows" class="headerlink" title="Flows"></a><strong>Flows</strong></h3><p>通过配置Flows可以将不同的<code>input</code>,<code>model</code>,<code>output</code>组合到一起</p>
<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><p>跑完板载的简单demo，可以配置比较复杂的任务了</p>
<p>Ti提供了一个叫做Model Downloader Tool[1]的工具，用来下载不同类型的预训练模型</p>
<p>运行下载器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@j7-evm:/opt/edge_ai_apps# ./download_models.sh</span><br></pre></td></tr></table></figure>
<p>是一个可交互界面，可以通过键盘选择想要下载的模型文件，其保存路径在<code>/opt/model/zoo</code></p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213513708.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213513708.png" alt=""></a><a target="_blank" rel="noopener" href="https://mmbiz.qpic.cn/mmbiz_png/ygGMicIOvEAR3ia0Ajtfb0EWoiaaZ2Mzwqibmm0iadu8S1OTBHEomLjU3IRRcXqJ0L4XZh6GxPGEtR5qwLlh72X6ZFQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" title="图片" class="gallery-item" style="box-shadow: none;"> <img src="https://mmbiz.qpic.cn/mmbiz_png/ygGMicIOvEAR3ia0Ajtfb0EWoiaaZ2Mzwqibmm0iadu8S1OTBHEomLjU3IRRcXqJ0L4XZh6GxPGEtR5qwLlh72X6ZFQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></a></p>
<h3 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h3><p>官方提供的模型肯定是不能满足个人业务需求的，所以自己训练模型并导入到tda4运行，是一个必然绕不开的路</p>
<p>Ti SDK提供了加载自定义模型的接口</p>
<p>•Tensorflow Lite•ONNX•TVM/Neo AI-DLR</p>
<p>每一个DNN模型需要满足以下结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TFL-OD-2010-ssd-mobV2-coco-mlperf-300x300│├── param.yaml│├── artifacts│   ├── 264_tidl_io_1.bin│   ├── 264_tidl_net.bin│   ├── 264_tidl_net.bin.layer_info.txt│   ├── 264_tidl_net.bin_netLog.txt│   ├── 264_tidl_net.bin.svg│   ├── allowedNode.txt│   └── runtimes_visualization.svg│└── model    └── ssd_mobilenet_v2_300_float.tflite</span><br></pre></td></tr></table></figure>
<p>•model</p>
<p>模型文件，例如tflite，onnx等</p>
<p>   •artifacts</p>
<p>由SDK编译生成出来的文件，网络层信息，量化信息，节点名称。</p>
<p>此部分是将模型转为TiDL模型中最为关键的一部分，Ti提供专门的文档[2]来解释这部分内容。</p>
<p>  •param.yaml  定义前处理，后处理等参数，例如anchor based和anchor free的后处理操作就很大不一样, 例如目标检测和语义分割对应的param格式就不一样，Ti提供了benchmark[3], 可以在里面找到对应的模板</p>
<p>SDK提供了一个工具叫做Edge AI TIDL Tools[4], 可以将通用模型转为Ti支持的DNN模型，目前支持三种模型的转换，但是<strong>Ti建议分别使用三种模型尝试转换，哪种模型的精度高就选用哪种模型做最终部署</strong></p>
<h3 id="References-1"><a href="#References-1" class="headerlink" title="References"></a>References</h3><p><code>[1]</code> Model Downloader Tool: <em><a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-modelzoo">https://github.com/TexasInstruments/edgeai-modelzoo</a></em><br><code>[2]</code> 文档: <em><a target="_blank" rel="noopener" href="https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/inference_models.html#pub-edgeai-compile-artifacts">https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/inference_models.html#pub-edgeai-compile-artifacts</a></em><br><code>[3]</code> benchmark: <em><a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-benchmark/tree/master/examples/configs/yaml">https://github.com/TexasInstruments/edgeai-benchmark/tree/master/examples/configs/yaml</a></em><br><code>[4]</code> Edge AI TIDL Tools: <em><a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/examples/osrt_python/README.md#model-compilation-on-pc">https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/examples/osrt_python/README.md#model-compilation-on-pc</a></em></p>
<h1 id="TDA4开发-三-运行demo"><a href="#TDA4开发-三-运行demo" class="headerlink" title="TDA4开发(三) 运行demo"></a>TDA4开发(三) 运行demo</h1><h3 id="TiDL-tools"><a href="#TiDL-tools" class="headerlink" title="TiDL-tools"></a>TiDL-tools</h3><p>在TDA4上进行inference的时候，主要是跑在A72和C71-MMA异构系统上，并不是单核完成。具体哪些操作在A核哪些操作在DSP核，需要在SDK编译时候配置。</p>
<p>TF-Lite[1]提供了TFLite Delgate API[2], TiDL可以很方便地去调用。ONNX和TVM则是调用标准API</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213740440.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213740440.png" alt=""></a></p>
<h3 id="WorkFlow"><a href="#WorkFlow" class="headerlink" title="WorkFlow"></a>WorkFlow</h3><p>以TFLite为例，TFLite的模型首先需要在PC上根据SDK生成Artifacts，然后再将模型和artifact一起作为输入，送到soc中完成推理任务</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213718806.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213718806.png" alt=""></a></p>
<h3 id="模型转换"><a href="#模型转换" class="headerlink" title="模型转换"></a>模型转换</h3><h3 id="1，在PC上搭建环境-3"><a href="#1，在PC上搭建环境-3" class="headerlink" title="1，在PC上搭建环境[3]"></a>1，在PC上搭建环境[3]</h3><p>建议Ubuntu18.04 + Python3.6， 模型转换只能通过python脚本完成</p>
<p>需要使用pip配置环境，需要先安装pip</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br></pre></td></tr></table></figure>
<p>下载代码，然后安装</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/TexasInstruments/edgeai-tidl-tools.gitexport DEVICE=j7#export DEVICE=am62   #设置DEVICEcd edgeai-tidl-toolssource ./setup.sh</span><br></pre></td></tr></table></figure>
<p>需要大量下载，时间会比较长</p>
<p>可能会在某个步骤安装出错，需要打开setup.sh，按照终端输出信息来重试几次。</p>
<p><strong>编译ONNX失败</strong></p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213831480.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213831480.png" alt=""></a></p>
<p>这是因为没有安装proto compillar</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install protobuf-compiler libprotoc-dev</span><br></pre></td></tr></table></figure>
<p>成功安装如图所示</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213921185.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724213921185.png" alt=""></a></p>
<p><strong>配置环境变量</strong></p>
<p>在代码里面有大量使用系统环境变量的地方，需要事先将环境变量设置好</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214059962.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214059962.png" alt=""></a><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214250591.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214250591.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export DEVICE=j7export TIDL_TOOLS_PATH=&quot;/home/lcg/tidl/edgeai-tidl-tools&quot;</span><br></pre></td></tr></table></figure>
<p>临时修改环境比那两只需要在shell中直接执行export即可，如果需要一劳永逸，添加到<code>~/.bahsrc</code>中即可</p>
<h3 id="2，验证环境是否可用"><a href="#2，验证环境是否可用" class="headerlink" title="2，验证环境是否可用"></a>2，<strong>验证环境是否可用</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./scripts/run_python_examples.sh</span><br></pre></td></tr></table></figure>
<p>脚本中包含了很多验证的过程，如果哪一步骤出错，可以单独验证</p>
<p>如果出现这种情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ValueError: could not load library libvx_tidl_rt.so</span><br></pre></td></tr></table></figure>
<p>或者下面这种情况</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214337266.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214337266.png" alt=""></a></p>
<p>需要在当前shell终端重新运行<code>source ./setup.sh</code>，配置当前终端环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/lcg/tidl/edgeai-tidl-tools/tidl_tools/tidl_graphVisualiser.out: error while loading shared libraries: libcgraph.so.6: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214547870.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214547870.png" alt=""></a></p>
<p>没有找到<code>libcgraph.so</code>库，如果安装过，则把路径添加到<code>$ld_LIBRARY_PATH</code>即可</p>
<p>如果没有安装过，则<code>sudo apt install graphviz</code></p>
<p><strong>使用python脚本验证example</strong></p>
<p>python脚本可以同时完成模型转换和推理验证</p>
<p>使用如下命令生成artifacts，并生成结果图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd examples/osrt_python/tflpython3 tflrt_delegate.py -c#具体 -c -d 参数可以参考代码</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214626003.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214626003.png" alt=""></a></p>
<p>如果能生成以上结果，就说明python运行example没有问题</p>
<p><strong>使用C++验证example</strong></p>
<p>C++的example只能完成推理验证，不能做模型转换。所以需要使用python代码生成的artifacts来做推理生成结果</p>
<p>C++的API需要读取<code>yaml</code>文件，所以需要单独安装一个库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libyaml-cpp-dev</span><br></pre></td></tr></table></figure>
<p>在<code>edgaai-tidl-tools</code>目录下创建<code>build</code>文件夹用来生成编译文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir build &amp;&amp; cd build</span><br></pre></td></tr></table></figure>
<p>在编译过程中，通过cmake设置参数来指定编译类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmake-gui ../example</span><br></pre></td></tr></table></figure>
<p>•TENSORFLOW_INSTALL_DIR : defaults check at ~/tensorflow•ONNXRT_INSTALL_DIR: defaults check at ~/onnxruntime•DLR_INSTALL_DIR: defaults check at ~/neo-ai-dlr•OPENCV_INSTALL_DIR: defaults check at ~/opencv-4.1.0•ARMNN_PATH: defaults check at ~/armnn•TARGET_FS_PATH: defaults check ~/targetfs•CROSS_COMPILER_PATH: defaults check ~/gcc-arm-9.2-2019.12-x86_64-aarch64-none-linux-gnu</p>
<p>这里采用默认配置即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#例如你要修改opencv路径#cmake -DOPENCV_INSTALL_DIR=&quot;/home/opencv4.1&quot; -DTARGET_CPU=arm ../examplesmake -jcd ../</span><br></pre></td></tr></table></figure>
<p>在repo的根目录生成bin文件夹</p>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214808478.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724214808478.png" alt=""></a></p>
<p>运行example</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># -f 指定artifacts，由python脚本生成# -i 指定输入图像./bin/Release/ort_main -f model-artifacts/od-ort-ssd-lite_mobilenetv2_fpn -i test_data/ADE_val_00001801.jpg</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724215013969.png" class="gallery-item" style="box-shadow: none;"> <img src="https://cdn.jsdelivr.net/gh/Bazingaliu/clouding@master/640-20220724215013969.png" alt=""></a></p>
<h3 id="3，SOC端推理"><a href="#3，SOC端推理" class="headerlink" title="3，SOC端推理"></a>3，SOC端推理</h3><p>在模型转化阶段生成的<code>artifacts</code>，此处就派上用场了</p>
<p>将文件夹拷贝到soc板，<code>./model-artifacts</code>,<code>models</code></p>
<p>这里的脚本只能验证流程是否跑通，并不能得到具体的精度数据，如果需要量化评估，需要参考ti 提供的benchmark[4]</p>
<h3 id="References-2"><a href="#References-2" class="headerlink" title="References"></a>References</h3><p><code>[1]</code> TF-Lite: <em><a target="_blank" rel="noopener" href="https://www.tensorflow.org/lite/guide/inference">https://www.tensorflow.org/lite/guide/inference</a></em><br><code>[2]</code> TFLite Delgate API: <em><a target="_blank" rel="noopener" href="https://www.tensorflow.org/lite/performance/delegates">https://www.tensorflow.org/lite/performance/delegates</a></em><br><code>[3]</code> 搭建环境: <em><a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/README.md#setup">https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/README.md#setup</a></em><br><code>[4]</code> benchmark: <em><a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-benchmark">https://github.com/TexasInstruments/edgeai-benchmark</a></em></p>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2022-07-24</span>
            
            
             
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                

                
                    <span class="post-footer-pre-next-last-span-right">下一篇：<a href="/2022/20220720/">ROS操作系统入门-3</a>
                    </span>
                
            </div>
    
        
    

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            © 1949-2025 China 

            
                

            
        </span>
       
    
</div>



<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>🌊看过大海的人不会忘记海的广阔🌊</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--目录-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--回到顶部按钮-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // 启用插件
            thumbnail: true,          // 显示缩略图
            zoom: true,               // 启用缩放功
            rotate: true,             // 启用旋转功能能
            autoplay: true,        // 启用自动播放功能
            fullScreen: true,      // 启用全屏功能
            pager: false, //页码,
            zoomFromOrigin: true,   // 从原始位置缩放
            actualSize: true,       // 启用查看实际大小的功能
            enableZoomAfter: 300,    // 延迟缩放，确保图片加载完成后可缩放
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // 修复选择器
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- 回到顶部的按钮-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- 返回的按钮-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>
<script src="/js/emojiHandler.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    wrapEmojis('.paper');
  });
</script>