<!DOCTYPE html>
<html lang="zh-CN">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="DeepLearning.ai笔记:(2-1)-- 深度学习的实践层面（Practical aspects of Deep Learning）" />
    <meta name="hexo-theme-A4" content="v1.9.8" />
    <link rel="alternate icon" type="image/webp" href="/img/20250602032635.jpg">
    <title>Yann | 我愿做你光华中淡淡的一笔</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--注意：首页既不是post也不是page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--返回顶部css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--目录-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


   
        
<link rel="stylesheet" href="/css/custom.css">

    

<meta name="generator" content="Hexo 5.4.2"></head>
    
    

    
    



    
        <style>
            .paper-main{
                max-width:  1200px;
            }
        </style>

    
    




    
    <style>
        :root {
            --waline-theme-color: #323e74; 
            --waline-color: #323e74; 
            --waline-border-color: #323e74; 
            --waline-white: #323e74; 
            --waline-bgcolor-light: #f2fafc;  
        }
        body {
            color: #323e74;
            background: #eaeae8;
        }
        .post-md code {
            background: #e7f7f3;
            color: #7f688d; 
        }
        .post-md pre, .post-md .highlight {
            background: #e7f7f3;
            color: #7f688d; 
        }
        pre .string, pre .value, pre .inheritance, pre .header, pre .ruby .symbol, pre .xml .cdata {
            color: #323e74;
        }
        pre .number, pre .preprocessor, pre .built_in, pre .literal, pre .params, pre .constant {
            color: #323e74;
        }
        .year-font-color {
            color: #323e74 !important;
        }
        .wl-card span.wl-nick {
            color: #323e74; 
        }
        .wl-card .wl-badge {
            border: 1px solid #323e74;
            color: #323e74; 
        }
        .wl-btn {
            border: 1px solid #323e74; 
            color:  #323e74;  
        }
        .wl-btn.primary {
            color: #f2fafc; 
        }
        .wl-header label {
            color: #323e74;
        }
        a {
            color: #7f688d;
        }

        .post-md a {
            color: #7f688d;
        }

        .nav li a {
            color: #7f688d;
        }

        .archive-main a:link {
            color: #7f688d;
        }
        .archive-main a:visited {
            color: #767c7c; 
        }

        .archive li span {
            color: #323e74;
        }

        .post-main-title {
            color: #323e74;
        }

        .post-md h1,
        .post-md h2,
        .post-md h3,
        .post-md h4,
        .post-md h5,
        .post-md h6 {
            color: #323e74;
        }

        [data-waline] p {
            color: #323e74;
        }
        [data-waline] a {
            color: #323e74;
        } 
        .wl-sort li.active {
            color: #323e74;
        }

        .wl-card .wl-meta>span {
            background: #f2fafc;
        }

        .paper {
            background: #eaeae8;
        }

        .index-main {
            background: #f2fafc;
        }

        .paper-main {
            background: #f2fafc;
        }

        .wl-panel {
            background: #f2fafc;
        }

        .archive li:nth-child(odd) {
            background: #f2fafc;
            ;
        }

        .archive li:nth-child(even) {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(odd) td {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(even) td {
            background: #f2fafc;
        }

    
        .progress-wrap::after {
            color: #323e74; /* 箭头的颜色 */
        }
        .progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* 边框的颜色 */
        }
        .progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* 鼠标滑过的箭头颜色 */
         }

        .return-to-last-progress-wrap::after {
            color: #323e74; /* 箭头的颜色 */
        }
        .return-to-last-progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* 边框的颜色 */
        }
        .return-to-last-progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* 鼠标滑过的箭头颜色 */
         }

         .left-toc-container::-webkit-scrollbar-thumb {
            background-color: #323e74; /* 设置滚动条拖动块的颜色 */
        }

        .bs-docs-sidebar .nav>.active>a,
        .bs-docs-sidebar .nav>li>a:hover,
        .bs-docs-sidebar .nav>li>a:focus {
            color: #7f688d;
            border-left-color: #7f688d;
        }
        .bs-docs-sidebar .nav>li>a {
            color:  #323e74;
        }
    </style>

    
    <style>
        body {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* 背景固定，不随页面滚动 */
            background-repeat: no-repeat;  /* 防止背景图片重复 */
            background-size: cover;       /* 背景自适应大小，覆盖整个背景 */
            background-position: center;   /* 背景居中显示 */
        }
        .paper {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* 背景固定，不随页面滚动 */
            background-repeat: no-repeat;  /* 防止背景图片重复 */
            background-size: cover;       /* 背景自适应大小，覆盖整个背景 */
            background-position: center;   /* 背景居中显示 */
        }  
    </style>


    
    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        <script>
            const options = {
                bottom: '40px', // default: '32px'
                right: 'unset', // default: '32px'
                left: '42px', // default: 'unset'
                time: '0.3s', // default: '0.3s'
                mixColor: '#fff', // default: '#fff'
                backgroundColor: ' #eaeae8  ',  // default: '#fff'
                buttonColorDark: '#100f2c',  // default: '#100f2c'
                buttonColorLight: '#fff', // default: '#fff'
                saveInCookies: true, // default: true,
                label: '🌓', // default: ''
                autoMatchOsTheme: true // default: true
            }
            const darkmode = new Darkmode(options);
            darkmode.showWidget();
        </script>
        
        
            
                <div class="left-toc-container">
                    <nav id="toc" class="bs-docs-sidebar"></nav>
                </div>
            
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <style>
            .header-img {
                width: 56px;
                height: auto;
                object-fit: cover; /* 保持图片比例 */
                transition: transform 0.3s ease-in-out; 
                border-radius: 0; 
            }
            
        </style>
        <img 
            alt="^-^" 
            cache-control="max-age=86400" 
            class="header-img" 
            src="/img/20250602032635.jpg" 
        />
        <div class="header-content">
            <a class="logo" href="/">Yann</a> 
            <span class="description">人工智能、计算机、机器学习、linux、程序员</span> 
        </div>
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">文章</a></li>
            
        
            
                <li><a href="/about/">关于</a></li>
            
        
            
                <li><a href="/tags/">标签</a></li>
            
        
            
                <li><a href="/categories/">分类</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    DeepLearning.ai笔记:(2-1)-- 深度学习的实践层面（Practical aspects of Deep Learning）
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>最近更新：2018-10-23</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>字数总计：1.8k</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>阅读估时：6分钟</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        阅读量：<span id="busuanzi_value_page_pv"></span>次
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E8%AE%AD%E7%BB%83%E3%80%81%E9%AA%8C%E8%AF%81%E3%80%81%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86"><span class="post-toc-text">训练、验证、测试集的划分</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#bias-and-variance%EF%BC%88%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE%EF%BC%89"><span class="post-toc-text">bias and variance（偏差和方差）</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#regularization%EF%BC%88%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%89"><span class="post-toc-text">regularization（正则化）</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%9F"><span class="post-toc-text">正则化如何防止过拟合？</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#dropout-%E6%AD%A3%E5%88%99%E5%8C%96"><span class="post-toc-text">dropout 正则化</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E7%90%86%E8%A7%A3dropout"><span class="post-toc-text">理解dropout</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96"><span class="post-toc-text">归一化</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="post-toc-text">参数初始化</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91"><span class="post-toc-text">梯度的数值逼近</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C"><span class="post-toc-text">梯度检验</span></a></li></ol>
            
        
        <div class=".article-gallery"><p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrl8dyhm4j218w0nstdc.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrl8dyhm4j218w0nstdc.jpg" alt=""></a></p>
<p>第二门课主要讲的是如何改善神经网络，通过超参数的调试、正则化以及优化。</p>
<p>第一周主要是说了一些之前机器学习里面涉及到的数据集的划分，以及初始化，正则化的方法，还有梯度的验证。</p>
<span id="more"></span>
<h1 id="训练、验证、测试集的划分"><a href="#训练、验证、测试集的划分" class="headerlink" title="训练、验证、测试集的划分"></a>训练、验证、测试集的划分</h1><p>这些在之前的机器学习课程中都讲过了，这里简单说一下。</p>
<p>训练集也就是你训练的样本；验证集是你训练之后的参数放到这些数据中做验证；而最后做的测试集则是相当于用来最终的测试。</p>
<p>一般来说，划分比例为60%/20%/20%就可以了，但是当数据越来越大，变成上百万，上千万的时候，那么验证集和测试集就没必要占那么大比重了，因为太过浪费，一般在0.5%-3%左右就可以。</p>
<p>需要注意的是，验证集和测试集的数据要来源相同，同分布，也就是同一类的数据，不能验证集是网上的，测试集是你自己拍的照片，这样误差会很大。</p>
<h1 id="bias-and-variance（偏差和方差）"><a href="#bias-and-variance（偏差和方差）" class="headerlink" title="bias and variance（偏差和方差）"></a>bias and variance（偏差和方差）</h1><p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9c7wej21440b6q46.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9c7wej21440b6q46.jpg" alt=""></a></p>
<p>high bias 表示的是高偏差，一般出现在欠拟合(under fitting)的情况下，</p>
<p>high variance表示高方差，一般出现在overfitting情况下。</p>
<p>如何解决呢：</p>
<ul>
<li>high bias<ul>
<li>更多的隐藏层</li>
<li>每一层更多的神经元</li>
</ul>
</li>
<li>high variance<ul>
<li>增加数据</li>
<li>正则化</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9dz6uj20n306y761.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9dz6uj20n306y761.jpg" alt=""></a></p>
<p>从左到右4种情况即是： high variance ;  high bias ; high bias and high variance ; low bias and low variance</p>
<h1 id="regularization（正则化）"><a href="#regularization（正则化）" class="headerlink" title="regularization（正则化）"></a>regularization（正则化）</h1><p>high variance可以使用正则化来解决。</p>
<p>我们知道，在logistic regression中的正则化项，是在损失函数后面加上：</p>
<p>L2 正则：$\frac{\lambda}{2m}||w||^{2}<em>{2} = \frac{\lambda}{2m}\sum</em>{j=1}^{n_{x}}{|w|} =  \frac{\lambda}{2m} w^T w$</p>
<p>L1正则：$\frac{\lambda}{2m}||w||<em>{1} = \frac{\lambda}{2m}\sum</em>{j=1}^{n_{x}}{|w|}$</p>
<p>一般用L2正则来做。</p>
<p>在neural network中，</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9c3lgj20sj07iq3i.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9c3lgj20sj07iq3i.jpg" alt=""></a></p>
<p>可以看到后面的正则式是从第1层累加到了第L层的所有神经网络的权重$||W^{[l]}||_{F}$的平方。</p>
<p>而我们知道这个W是一个$n^{[l]} * n^{[l-1]}$的矩阵，那么</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9bolcj20nh02v0st.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9bolcj20nh02v0st.jpg" alt=""></a></p>
<p>它表示矩阵中所有元素的平方和。也就这一项嵌套了3层的$\sum$。</p>
<p>那么，如何实现这个范数的梯度下降呢？</p>
<p>在原本的backprop中,加上的正则项的导数，$dJ / dW$</p>
<p>$$dW^{[l]} = (form backprop) + \frac{\lambda}{m}W^{[l]}$$</p>
<p>代入</p>
<p>$$W^{[l]} = W^{[l]} - \alpha dW^{[l]}$$</p>
<p>得到：</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9ktwij20hb05jmxc.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9ktwij20hb05jmxc.jpg" alt=""></a></p>
<p>可以看到，$(1 - \frac{\alpha \lambda}{m}) &lt; 1$，所以每一次都会让W变小，因此L2范数正则化也成为“权重衰减”</p>
<h2 id="正则化如何防止过拟合？"><a href="#正则化如何防止过拟合？" class="headerlink" title="正则化如何防止过拟合？"></a>正则化如何防止过拟合？</h2><p>直观理解是在代价函数加入正则项后，如果$\lambda$非常大，为了满足代价函数最小化，那么$w^{[l]}$这一项必须非常接近于0，所以就等价于很多神经元都没有作用了，从原本的非线性结构变成了近似的线性结构，自然就不会过拟合了。</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9cnavj20to0dqwfw.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9cnavj20to0dqwfw.jpg" alt=""></a></p>
<p>我们再来直观感受一下，</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9bx7jj20dg06fgll.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9bx7jj20dg06fgll.jpg" alt=""></a></p>
<p>假设是一个tanh()函数，那么$z = wx + b$，当w非常接近于0时，z也接近于0，也就是在坐标轴上0附近范围内，这个时候斜率接近于线性，那么整个神经网络也非常接近于线性的网络，那么就不会发生过拟合了。</p>
<h2 id="dropout-正则化"><a href="#dropout-正则化" class="headerlink" title="dropout 正则化"></a>dropout 正则化</h2><p>dropout(随机失活)，也是正则化的一种，顾名思义，是让神经网络中的神经元按照一定的概率随机失活。</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9rth2j20qs0ae753.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9rth2j20qs0ae753.jpg" alt=""></a></p>
<p><strong>实现dropout：inverted dropout（反向随机失活）</strong></p>
<p>实现dropout有好几种，但是最常用的还是这个inverted dropout</p>
<p>假设是一个3层的神经网络，keepprob表示保留节点的概率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keepprob = <span class="number">0.8</span></span><br><span class="line"><span class="comment">#d3是矩阵，每个元素有true,false,在python中代表1和0</span></span><br><span class="line">d3 = np.random.rand(a3.shape[<span class="number">0</span>],a3.shape[<span class="number">1</span>]) &lt; keepprob</span><br><span class="line">a3 = np.multiply(a3,d3)</span><br><span class="line">a3 /= keepprob</span><br></pre></td></tr></table></figure>
<p>其中第4式 $a3 /= keepprob$</p>
<p>假设第三层有50个神经元 a3.shape[0] = 50，一共有 $50 * m$维，m是样本数，这样子就会有平均10个神经元被删除，因为$z^{[4]} = w^{[4]} a^{[3]} + b^{[4]}$，那么这个时候$z^{[4]}$的期望值就少了20%,所以在每个神经元上都除以keepprob的值，刚好弥补的之前的损失。</p>
<p><strong>注意</strong></p>
<p>在test阶段，就不需要再使用dropout了，而是像之前一样，直接乘以各个层的权重，得出预测值就可以。</p>
<h2 id="理解dropout"><a href="#理解dropout" class="headerlink" title="理解dropout"></a>理解dropout</h2><p>直观上，因为神经元有可能会被随机清除，这样子在训练中，就不会过分依赖某一个神经元或者特征的权重。</p>
<p>当然可以设置不同层有不同的dropout概率。</p>
<p>计算机视觉领域非常喜欢用这个dropout。</p>
<p>但是这个东西的一大缺点就是代价函数J不能再被明确定义，每次都会随机移除一些节点，所以很难进行复查。如果需要调试的话，通常会关闭dropout，设置为1，这样再来debug。</p>
<h1 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h1><p>归一化数据可以加速神经网络的训练速度。</p>
<p>一般有两个步骤：</p>
<ul>
<li>零均值</li>
<li>归一化方差</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9itq1j20u50fct9t.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9itq1j20u50fct9t.jpg" alt=""></a></p>
<p>这样子在gradient的时候就会走的顺畅一点：</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9ildoj20tu0gpacs.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9ildoj20tu0gpacs.jpg" alt=""></a></p>
<h1 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h1><p>合理的参数初始化可以有效的加快神经网络的训练速度。</p>
<p>一般呢$z = w_1 x_1 + w_2 x_2 + … + w_n x_n$，一般希望z不要太大也不要太小。所以呢，希望n越大，w越小才好。最合理的就是方差 $w = \frac{1}{n}$，所以：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WL = np.random.randn(WL.shape[0],WL.shape[1])* np.sqrt(1/n)</span><br></pre></td></tr></table></figure>
<p>这个$n$即$n^{[l-1]}$</p>
<p>如果是relu函数，</p>
<p>那么 $w = \frac{2}{n}$比较好，也就是<code>np.sqrt(2/n)</code></p>
<h1 id="梯度的数值逼近"><a href="#梯度的数值逼近" class="headerlink" title="梯度的数值逼近"></a>梯度的数值逼近</h1><p>$$ \frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} $$</p>
<p>微积分的常识，用$\varepsilon$来逼近梯度。</p>
<h1 id="梯度检验"><a href="#梯度检验" class="headerlink" title="梯度检验"></a>梯度检验</h1><p>用梯度检验可以来检查在反向传播中的算法有没有错误。</p>
<p>这个时候，可以把$W^{[1]},b^{[1]},……W^{[l]},b^{[l]}$变成一个向量，这样可以得到一个代价函数$J(\theta)$，然后$dW,db$也可以转换成一个向量，用$d\theta$表示，和$\theta$有相同的维度。</p>
<p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9f9tnj20t70gqwfq.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrlk9f9tnj20t70gqwfq.jpg" alt=""></a></p>
<p>再对每一个$d\theta_{approx}[i]$求上面的双边梯度逼近，然后也用导数求得每一个$d\theta[i]$，然后根据图上的cheak公式。求梯度逼近的时候，设置两边的$\varepsilon = 10^{-7}$，最终求得的值如果是$10^{-7}$，那么很正常，$10^{-3}$就是错了的，如果是$10^{-5}$，那么就需要斟酌一下了。</p>
<p><strong>注意</strong></p>
<ul>
<li>不要在训练中用梯度检验，因为很慢</li>
<li>如果发现有问题，那么定位到误差比较大的那一层查看</li>
<li>如果有正则化，记得加入正则项</li>
<li>不要和dropout一起使用，因为dropout本来就不容易计算梯度。</li>
</ul>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2018-09-15</span>
            
                <span>该篇文章被 Yann</span>
            
            
                <span>打上标签:
                    
                    
                        <a href='/tags/dl-ai/'>
                            dl.ai
                        </a>
                    
                </span>
             
             
                <span>归为分类:
                    
                    
                        <a href='/categories/AI/'>
                            AI
                        </a>
                    
                </span>
            
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                
                    <span>上一篇：<a href='/2018/2018091515/'>DeepLearning.ai作业:(2-1)-- 深度学习的实践层面（Practical aspects of Deep Learning）</a></span>
                

                
                    <span class="post-footer-pre-next-last-span-right">下一篇：<a href="/2018/2018091318/">DeepLearning.ai作业:(1-4)-- 深层神经网络（Deep neural networks）</a>
                    </span>
                
            </div>
    
        
    

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            © 1949-2025 China 

            
                

            
        </span>
       
    
</div>



<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>🌊看过大海的人不会忘记海的广阔🌊</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--目录-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--回到顶部按钮-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // 启用插件
            thumbnail: true,          // 显示缩略图
            zoom: true,               // 启用缩放功
            rotate: true,             // 启用旋转功能能
            autoplay: true,        // 启用自动播放功能
            fullScreen: true,      // 启用全屏功能
            pager: false, //页码,
            zoomFromOrigin: true,   // 从原始位置缩放
            actualSize: true,       // 启用查看实际大小的功能
            enableZoomAfter: 300,    // 延迟缩放，确保图片加载完成后可缩放
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // 修复选择器
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- 回到顶部的按钮-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- 返回的按钮-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>
<script src="/js/emojiHandler.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    wrapEmojis('.paper');
  });
</script>