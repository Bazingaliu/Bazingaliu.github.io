<!DOCTYPE html>
<html lang="zh-CN">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="DeepLearning.aiä½œä¸š:(2-3)-- è¶…å‚æ•°è°ƒè¯•ï¼ˆHyperparameter tuningï¼‰" />
    <meta name="hexo-theme-A4" content="v1.9.8" />
    <link rel="alternate icon" type="image/webp" href="/img/20250602032635.jpg">
    <title>Yann | æˆ‘æ„¿åšä½ å…‰åä¸­æ·¡æ·¡çš„ä¸€ç¬”</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--æ³¨æ„ï¼šé¦–é¡µæ—¢ä¸æ˜¯postä¹Ÿä¸æ˜¯page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--è¿”å›é¡¶éƒ¨css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--ç›®å½•-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


   
        
<link rel="stylesheet" href="/css/custom.css">

    

<meta name="generator" content="Hexo 5.4.2"></head>
    
    

    
    



    
        <style>
            .paper-main{
                max-width:  1200px;
            }
        </style>

    
    




    
    <style>
        :root {
            --waline-theme-color: #323e74; 
            --waline-color: #323e74; 
            --waline-border-color: #323e74; 
            --waline-white: #323e74; 
            --waline-bgcolor-light: #f2fafc;  
        }
        body {
            color: #323e74;
            background: #eaeae8;
        }
        .post-md code {
            background: #e7f7f3;
            color: #7f688d; 
        }
        .post-md pre, .post-md .highlight {
            background: #e7f7f3;
            color: #7f688d; 
        }
        pre .string, pre .value, pre .inheritance, pre .header, pre .ruby .symbol, pre .xml .cdata {
            color: #323e74;
        }
        pre .number, pre .preprocessor, pre .built_in, pre .literal, pre .params, pre .constant {
            color: #323e74;
        }
        .year-font-color {
            color: #323e74 !important;
        }
        .wl-card span.wl-nick {
            color: #323e74; 
        }
        .wl-card .wl-badge {
            border: 1px solid #323e74;
            color: #323e74; 
        }
        .wl-btn {
            border: 1px solid #323e74; 
            color:  #323e74;  
        }
        .wl-btn.primary {
            color: #f2fafc; 
        }
        .wl-header label {
            color: #323e74;
        }
        a {
            color: #7f688d;
        }

        .post-md a {
            color: #7f688d;
        }

        .nav li a {
            color: #7f688d;
        }

        .archive-main a:link {
            color: #7f688d;
        }
        .archive-main a:visited {
            color: #767c7c; 
        }

        .archive li span {
            color: #323e74;
        }

        .post-main-title {
            color: #323e74;
        }

        .post-md h1,
        .post-md h2,
        .post-md h3,
        .post-md h4,
        .post-md h5,
        .post-md h6 {
            color: #323e74;
        }

        [data-waline] p {
            color: #323e74;
        }
        [data-waline] a {
            color: #323e74;
        } 
        .wl-sort li.active {
            color: #323e74;
        }

        .wl-card .wl-meta>span {
            background: #f2fafc;
        }

        .paper {
            background: #eaeae8;
        }

        .index-main {
            background: #f2fafc;
        }

        .paper-main {
            background: #f2fafc;
        }

        .wl-panel {
            background: #f2fafc;
        }

        .archive li:nth-child(odd) {
            background: #f2fafc;
            ;
        }

        .archive li:nth-child(even) {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(odd) td {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(even) td {
            background: #f2fafc;
        }

    
        .progress-wrap::after {
            color: #323e74; /* ç®­å¤´çš„é¢œè‰² */
        }
        .progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* è¾¹æ¡†çš„é¢œè‰² */
        }
        .progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* é¼ æ ‡æ»‘è¿‡çš„ç®­å¤´é¢œè‰² */
         }

        .return-to-last-progress-wrap::after {
            color: #323e74; /* ç®­å¤´çš„é¢œè‰² */
        }
        .return-to-last-progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* è¾¹æ¡†çš„é¢œè‰² */
        }
        .return-to-last-progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* é¼ æ ‡æ»‘è¿‡çš„ç®­å¤´é¢œè‰² */
         }

         .left-toc-container::-webkit-scrollbar-thumb {
            background-color: #323e74; /* è®¾ç½®æ»šåŠ¨æ¡æ‹–åŠ¨å—çš„é¢œè‰² */
        }

        .bs-docs-sidebar .nav>.active>a,
        .bs-docs-sidebar .nav>li>a:hover,
        .bs-docs-sidebar .nav>li>a:focus {
            color: #7f688d;
            border-left-color: #7f688d;
        }
        .bs-docs-sidebar .nav>li>a {
            color:  #323e74;
        }
    </style>

    
    <style>
        body {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* èƒŒæ™¯å›ºå®šï¼Œä¸éšé¡µé¢æ»šåŠ¨ */
            background-repeat: no-repeat;  /* é˜²æ­¢èƒŒæ™¯å›¾ç‰‡é‡å¤ */
            background-size: cover;       /* èƒŒæ™¯è‡ªé€‚åº”å¤§å°ï¼Œè¦†ç›–æ•´ä¸ªèƒŒæ™¯ */
            background-position: center;   /* èƒŒæ™¯å±…ä¸­æ˜¾ç¤º */
        }
        .paper {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* èƒŒæ™¯å›ºå®šï¼Œä¸éšé¡µé¢æ»šåŠ¨ */
            background-repeat: no-repeat;  /* é˜²æ­¢èƒŒæ™¯å›¾ç‰‡é‡å¤ */
            background-size: cover;       /* èƒŒæ™¯è‡ªé€‚åº”å¤§å°ï¼Œè¦†ç›–æ•´ä¸ªèƒŒæ™¯ */
            background-position: center;   /* èƒŒæ™¯å±…ä¸­æ˜¾ç¤º */
        }  
    </style>


    
    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        <script>
            const options = {
                bottom: '40px', // default: '32px'
                right: 'unset', // default: '32px'
                left: '42px', // default: 'unset'
                time: '0.3s', // default: '0.3s'
                mixColor: '#fff', // default: '#fff'
                backgroundColor: ' #eaeae8  ',  // default: '#fff'
                buttonColorDark: '#100f2c',  // default: '#100f2c'
                buttonColorLight: '#fff', // default: '#fff'
                saveInCookies: true, // default: true,
                label: 'ğŸŒ“', // default: ''
                autoMatchOsTheme: true // default: true
            }
            const darkmode = new Darkmode(options);
            darkmode.showWidget();
        </script>
        
        
            
                <div class="left-toc-container">
                    <nav id="toc" class="bs-docs-sidebar"></nav>
                </div>
            
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <style>
            .header-img {
                width: 56px;
                height: auto;
                object-fit: cover; /* ä¿æŒå›¾ç‰‡æ¯”ä¾‹ */
                transition: transform 0.3s ease-in-out; 
                border-radius: 0; 
            }
            
        </style>
        <img 
            alt="^-^" 
            cache-control="max-age=86400" 
            class="header-img" 
            src="/img/20250602032635.jpg" 
        />
        <div class="header-content">
            <a class="logo" href="/">Yann</a> 
            <span class="description">äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºã€æœºå™¨å­¦ä¹ ã€linuxã€ç¨‹åºå‘˜</span> 
        </div>
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">é¦–é¡µ</a></li>
            
        
            
                <li><a href="/list/">æ–‡ç« </a></li>
            
        
            
                <li><a href="/about/">å…³äº</a></li>
            
        
            
                <li><a href="/tags/">æ ‡ç­¾</a></li>
            
        
            
                <li><a href="/categories/">åˆ†ç±»</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--è¯´æ˜æ˜¯æ–‡ç« posté¡µé¢-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    DeepLearning.aiä½œä¸š:(2-3)-- è¶…å‚æ•°è°ƒè¯•ï¼ˆHyperparameter tuningï¼‰
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>æœ€è¿‘æ›´æ–°ï¼š2018-10-23</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>å­—æ•°æ€»è®¡ï¼š1.9k</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>é˜…è¯»ä¼°æ—¶ï¼š11åˆ†é’Ÿ</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        é˜…è¯»é‡ï¼š<span id="busuanzi_value_page_pv"></span>æ¬¡
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Building-neural-network"><span class="post-toc-text">Building neural network</span></a></li></ol>
            
        
        <div class=".article-gallery"><p><a target="_blank" rel="noopener" href="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrl8dyhm4j218w0nstdc.jpg" class="gallery-item" style="box-shadow: none;"> <img src="http://ww1.sinaimg.cn/large/d40b6c29gy1fvrl8dyhm4j218w0nstdc.jpg" alt=""></a></p>
<ol>
<li>ä¸è¦æŠ„ä½œä¸šï¼</li>
<li>æˆ‘åªæ˜¯æŠŠæ€è·¯æ•´ç†äº†ï¼Œä¾›ä¸ªäººå­¦ä¹ ã€‚</li>
<li>ä¸è¦æŠ„ä½œä¸šï¼</li>
</ol>
<p>æœ¬å‘¨ä¸»è¦æ˜¯TensorFlowçš„ç®€å•æ•™ç¨‹ï¼Œæ²¡ä»€ä¹ˆå¥½è¯´çš„ï¼Œå¯ä»¥å»çœ‹çœ‹æ›´è¯¦ç»†ä¸€ç‚¹çš„æ•™ç¨‹ã€‚</p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: linear_function</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_function</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements a linear function: </span></span><br><span class="line"><span class="string">            Initializes W to be a random tensor of shape (4,3)</span></span><br><span class="line"><span class="string">            Initializes X to be a random tensor of shape (3,1)</span></span><br><span class="line"><span class="string">            Initializes b to be a random tensor of shape (4,1)</span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    result -- runs the session for Y = WX + b </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (4 lines of code)</span></span><br><span class="line">    X = tf.constant(np.random.randn(<span class="number">3</span>,<span class="number">1</span>), name = <span class="string">&quot;X&quot;</span>)</span><br><span class="line">    W = tf.constant(np.random.randn(<span class="number">4</span>,<span class="number">3</span>), name = <span class="string">&quot;W&quot;</span>)</span><br><span class="line">    b = tf.constant(np.random.randn(<span class="number">4</span>,<span class="number">1</span>), name = <span class="string">&quot;b&quot;</span>)</span><br><span class="line">    Y = tf.matmul(W,X) + b</span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    result = sess.run(Y)</span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># close the session </span></span><br><span class="line">    sess.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sigmoid</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">z</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes the sigmoid of z</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    z -- input value, scalar or vector</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    results -- the sigmoid of z</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### ( approx. 4 lines of code)</span></span><br><span class="line">    <span class="comment"># Create a placeholder for x. Name it &#x27;x&#x27;.</span></span><br><span class="line">    x = tf.placeholder(tf.float32,name=<span class="string">&quot;x&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute sigmoid(x)</span></span><br><span class="line">    sigmoid = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a session, and run it. Please use the method 2 explained above. </span></span><br><span class="line">    <span class="comment"># You should use a feed_dict to pass z&#x27;s value to x. </span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># Run session and call the output &quot;result&quot;</span></span><br><span class="line">        result = sess.run(sigmoid,feed_dict=&#123;x:z&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: cost</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span>(<span class="params">logits, labels</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Â Â Â Â Computes the cost using the sigmoid cross entropy</span></span><br><span class="line"><span class="string">Â Â Â Â </span></span><br><span class="line"><span class="string">Â Â Â Â Arguments:</span></span><br><span class="line"><span class="string">Â Â Â Â logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)</span></span><br><span class="line"><span class="string">Â Â Â Â labels -- vector of labels y (1 or 0) </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Note: What we&#x27;ve been calling &quot;z&quot; and &quot;y&quot; in this class are respectively called &quot;logits&quot; and &quot;labels&quot; </span></span><br><span class="line"><span class="string">    in the TensorFlow documentation. So logits will feed into z, and labels into y. </span></span><br><span class="line"><span class="string">Â Â Â Â </span></span><br><span class="line"><span class="string">Â Â Â Â Returns:</span></span><br><span class="line"><span class="string">Â Â Â Â cost -- runs the session of the cost (formula (2))</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the placeholders for &quot;logits&quot; (z) and &quot;labels&quot; (y) (approx. 2 lines)</span></span><br><span class="line">    z = tf.placeholder(tf.float32,name=<span class="string">&quot;z&quot;</span>)</span><br><span class="line">    y = tf.placeholder(tf.float32,name=<span class="string">&quot;y&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Use the loss function (approx. 1 line)</span></span><br><span class="line">    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z,labels=y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the session (approx. 1 line).</span></span><br><span class="line">    cost = sess.run(cost,feed_dict=&#123;z:logits,y:labels&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Close the session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess.close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: one_hot_matrix</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot_matrix</span>(<span class="params">labels, C</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Creates a matrix where the i-th row corresponds to the ith class number and the jth column</span></span><br><span class="line"><span class="string">                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) </span></span><br><span class="line"><span class="string">                     will be 1. </span></span><br><span class="line"><span class="string">                     </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    labels -- vector containing the labels </span></span><br><span class="line"><span class="string">    C -- number of classes, the depth of the one hot dimension</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    one_hot -- one hot matrix</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create a tf.constant equal to C (depth), name it &#x27;C&#x27;. (approx. 1 line)</span></span><br><span class="line">    C = tf.constant(C)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Use tf.one_hot, be careful with the axis (approx. 1 line)</span></span><br><span class="line">    one_hot_matrix = tf.one_hot(labels, C, axis = <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the session (approx. 1 line)</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the session (approx. 1 line)</span></span><br><span class="line">    one_hot = sess.run(one_hot_matrix)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Close the session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess.close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> one_hot</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: ones</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ones</span>(<span class="params">shape</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Creates an array of ones of dimension shape</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    shape -- shape of the array you want to create</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    ones -- array containing only ones</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create &quot;ones&quot; tensor using tf.ones(...). (approx. 1 line)</span></span><br><span class="line">    ones = tf.ones(shape)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create the session (approx. 1 line)</span></span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the session to compute &#x27;ones&#x27; (approx. 1 line)</span></span><br><span class="line">    ones = sess.run(ones)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Close the session (approx. 1 line). See method 1 above.</span></span><br><span class="line">    sess.close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> ones</span><br></pre></td></tr></table></figure>
<h1 id="Building-neural-network"><a href="#Building-neural-network" class="headerlink" title="Building neural network"></a>Building neural network</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: create_placeholders</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_placeholders</span>(<span class="params">n_x, n_y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Creates the placeholders for the tensorflow session.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)</span></span><br><span class="line"><span class="string">    n_y -- scalar, number of classes (from 0 to 5, so -&gt; 6)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- placeholder for the data input, of shape [n_x, None] and dtype &quot;float&quot;</span></span><br><span class="line"><span class="string">    Y -- placeholder for the input labels, of shape [n_y, None] and dtype &quot;float&quot;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Tips:</span></span><br><span class="line"><span class="string">    - You will use None because it let&#x27;s us be flexible on the number of examples you will for the placeholders.</span></span><br><span class="line"><span class="string">      In fact, the number of examples during test/train is different.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 2 lines)</span></span><br><span class="line">    X = tf.placeholder(tf.float32,[n_x,<span class="literal">None</span>])</span><br><span class="line">    Y = tf.placeholder(tf.float32,[n_y,<span class="literal">None</span>])</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: initialize_parameters</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Initializes parameters to build a neural network with tensorflow. The shapes are:</span></span><br><span class="line"><span class="string">                        W1 : [25, 12288]</span></span><br><span class="line"><span class="string">                        b1 : [25, 1]</span></span><br><span class="line"><span class="string">                        W2 : [12, 25]</span></span><br><span class="line"><span class="string">                        b2 : [12, 1]</span></span><br><span class="line"><span class="string">                        W3 : [6, 12]</span></span><br><span class="line"><span class="string">                        b3 : [6, 1]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                   <span class="comment"># so that your &quot;random&quot; numbers match ours</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 6 lines of code)</span></span><br><span class="line">    W1 =  tf.get_variable(<span class="string">&quot;W1&quot;</span>, [<span class="number">25</span>,<span class="number">12288</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">    b1 = tf.get_variable(<span class="string">&quot;b1&quot;</span>, [<span class="number">25</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br><span class="line">    W2 = tf.get_variable(<span class="string">&quot;W2&quot;</span>, [<span class="number">12</span>,<span class="number">25</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">    b2 = tf.get_variable(<span class="string">&quot;b2&quot;</span>, [<span class="number">12</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br><span class="line">    W3 = tf.get_variable(<span class="string">&quot;W3&quot;</span>, [<span class="number">6</span>,<span class="number">12</span>], initializer = tf.contrib.layers.xavier_initializer(seed = <span class="number">1</span>))</span><br><span class="line">    b3 = tf.get_variable(<span class="string">&quot;b3&quot;</span>, [<span class="number">6</span>,<span class="number">1</span>], initializer = tf.zeros_initializer())</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    parameters = &#123;<span class="string">&quot;W1&quot;</span>: W1,</span><br><span class="line">                  <span class="string">&quot;b1&quot;</span>: b1,</span><br><span class="line">                  <span class="string">&quot;W2&quot;</span>: W2,</span><br><span class="line">                  <span class="string">&quot;b2&quot;</span>: b2,</span><br><span class="line">                  <span class="string">&quot;W3&quot;</span>: W3,</span><br><span class="line">                  <span class="string">&quot;b3&quot;</span>: b3&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: forward_propagation</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span>(<span class="params">X, parameters</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements the forward propagation for the model: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SOFTMAX</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input dataset placeholder, of shape (input size, number of examples)</span></span><br><span class="line"><span class="string">    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, &quot;W2&quot;, &quot;b2&quot;, &quot;W3&quot;, &quot;b3&quot;</span></span><br><span class="line"><span class="string">                  the shapes are given in initialize_parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    Z3 -- the output of the last LINEAR unit</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve the parameters from the dictionary &quot;parameters&quot; </span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line">    W3 = parameters[<span class="string">&#x27;W3&#x27;</span>]</span><br><span class="line">    b3 = parameters[<span class="string">&#x27;b3&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:</span></span><br><span class="line">    Z1 = tf.matmul(W1,X) + b1                                              <span class="comment"># Z1 = np.dot(W1, X) + b1</span></span><br><span class="line">    A1 = tf.nn.relu(Z1)                                              <span class="comment"># A1 = relu(Z1)</span></span><br><span class="line">    Z2 = tf.matmul(W2,A1) + b2                                              <span class="comment"># Z2 = np.dot(W2, a1) + b2</span></span><br><span class="line">    A2 = tf.nn.relu(Z2)                                              <span class="comment"># A2 = relu(Z2)</span></span><br><span class="line">    Z3 = tf.matmul(W3,A2) + b3                                              <span class="comment"># Z3 = np.dot(W3,Z2) + b3</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Z3</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: compute_cost </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span>(<span class="params">Z3, Y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes the cost</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)</span></span><br><span class="line"><span class="string">    Y -- &quot;true&quot; labels vector placeholder, same shape as Z3</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    cost - Tensor of the cost function</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)</span></span><br><span class="line">    logits = tf.transpose(Z3)</span><br><span class="line">    labels = tf.transpose(Y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line of code)</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits =logits, labels = labels))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span>(<span class="params">X_train, Y_train, X_test, Y_test, learning_rate = <span class="number">0.0001</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">          num_epochs = <span class="number">1500</span>, minibatch_size = <span class="number">32</span>, print_cost = <span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements a three-layer tensorflow neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SOFTMAX.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)</span></span><br><span class="line"><span class="string">    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)</span></span><br><span class="line"><span class="string">    X_test -- training set, of shape (input size = 12288, number of training examples = 120)</span></span><br><span class="line"><span class="string">    Y_test -- test set, of shape (output size = 6, number of test examples = 120)</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the optimization</span></span><br><span class="line"><span class="string">    num_epochs -- number of epochs of the optimization loop</span></span><br><span class="line"><span class="string">    minibatch_size -- size of a minibatch</span></span><br><span class="line"><span class="string">    print_cost -- True to print the cost every 100 epochs</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    parameters -- parameters learnt by the model. They can then be used to predict.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    ops.reset_default_graph()                         <span class="comment"># to be able to rerun the model without overwriting tf variables</span></span><br><span class="line">    tf.set_random_seed(<span class="number">1</span>)                             <span class="comment"># to keep consistent results</span></span><br><span class="line">    seed = <span class="number">3</span>                                          <span class="comment"># to keep consistent results</span></span><br><span class="line">    (n_x, m) = X_train.shape                          <span class="comment"># (n_x: input size, m : number of examples in the train set)</span></span><br><span class="line">    n_y = Y_train.shape[<span class="number">0</span>]                            <span class="comment"># n_y : output size</span></span><br><span class="line">    costs = []                                        <span class="comment"># To keep track of the cost</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create Placeholders of shape (n_x, n_y)</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    X, Y = create_placeholders(n_x,n_y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize parameters</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    parameters = initialize_parameters()</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Forward propagation: Build the forward propagation in the tensorflow graph</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    Z3 = forward_propagation(X, parameters)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Cost function: Add cost function to tensorflow graph</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    cost = compute_cost(Z3, Y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">    optimizer = optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize all the variables</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start the session to compute the tensorflow graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Run the initialization</span></span><br><span class="line">        sess.run(init)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Do the training loop</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line"></span><br><span class="line">            epoch_cost = <span class="number">0.</span>                       <span class="comment"># Defines a cost related to an epoch</span></span><br><span class="line">            num_minibatches = <span class="built_in">int</span>(m / minibatch_size) <span class="comment"># number of minibatches of size minibatch_size in the train set</span></span><br><span class="line">            seed = seed + <span class="number">1</span></span><br><span class="line">            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> minibatch <span class="keyword">in</span> minibatches:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Select a minibatch</span></span><br><span class="line">                (minibatch_X, minibatch_Y) = minibatch</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># IMPORTANT: The line that runs the graph on a minibatch.</span></span><br><span class="line">                <span class="comment"># Run the session to execute the &quot;optimizer&quot; and the &quot;cost&quot;, the feedict should contain a minibatch for (X,Y).</span></span><br><span class="line">                <span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = &#123;X: minibatch_X, Y: minibatch_Y&#125;)</span><br><span class="line">                <span class="comment">### END CODE HERE ###</span></span><br><span class="line">                </span><br><span class="line">                epoch_cost += minibatch_cost / num_minibatches</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Print the cost every epoch</span></span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span> (<span class="string">&quot;Cost after epoch %i: %f&quot;</span> % (epoch, epoch_cost))</span><br><span class="line">            <span class="keyword">if</span> print_cost == <span class="literal">True</span> <span class="keyword">and</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">                costs.append(epoch_cost)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># plot the cost</span></span><br><span class="line">        plt.plot(np.squeeze(costs))</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;cost&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;iterations (per tens)&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;Learning rate =&quot;</span> + <span class="built_in">str</span>(learning_rate))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># lets save the parameters in a variable</span></span><br><span class="line">        parameters = sess.run(parameters)</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Parameters have been trained!&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the correct predictions</span></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate accuracy on the test set</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">&quot;float&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Train Accuracy:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;X: X_train, Y: Y_train&#125;))</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Test Accuracy:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;X: X_test, Y: Y_test&#125;))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2018-09-18</span>
            
                <span>è¯¥ç¯‡æ–‡ç« è¢« Yann</span>
            
            
                <span>æ‰“ä¸Šæ ‡ç­¾:
                    
                    
                        <a href='/tags/homework/'>
                            homework
                        </a>
                    
                        <a href='/tags/dl-ai/'>
                            dl.ai
                        </a>
                    
                </span>
             
             
                <span>å½’ä¸ºåˆ†ç±»:
                    
                    
                        <a href='/categories/AI/'>
                            AI
                        </a>
                    
                </span>
            
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                
                    <span>ä¸Šä¸€ç¯‡ï¼š<a href='/2018/2018092016/'>DeepLearning.aiç¬”è®°:(3-1)-- æœºå™¨å­¦ä¹ ç­–ç•¥(1)(ML strategy)</a></span>
                

                
                    <span class="post-footer-pre-next-last-span-right">ä¸‹ä¸€ç¯‡ï¼š<a href="/2018/2018091720/">DeepLearning.aiç¬”è®°:(2-3)-- è¶…å‚æ•°è°ƒè¯•ï¼ˆHyperparameter tuningï¼‰</a>
                    </span>
                
            </div>
    
        
    

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            Â© 1949-2025 China 

            
                

            
        </span>
       
    
</div>



<!--è¿™æ˜¯æŒ‡ä¸€æ¡çº¿å¾€ä¸‹çš„å†…å®¹-->
<div class="footer-last">
    
            <span>ğŸŒŠçœ‹è¿‡å¤§æµ·çš„äººä¸ä¼šå¿˜è®°æµ·çš„å¹¿é˜”ğŸŒŠ</span>
            
                <span class="footer-last-span-right"><i>æœ¬ç«™ç”±<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>é©±åŠ¨ï½œä½¿ç”¨<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>ä¸»é¢˜</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--ç›®å½•-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--å›åˆ°é¡¶éƒ¨æŒ‰é’®-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // å¯ç”¨æ’ä»¶
            thumbnail: true,          // æ˜¾ç¤ºç¼©ç•¥å›¾
            zoom: true,               // å¯ç”¨ç¼©æ”¾åŠŸ
            rotate: true,             // å¯ç”¨æ—‹è½¬åŠŸèƒ½èƒ½
            autoplay: true,        // å¯ç”¨è‡ªåŠ¨æ’­æ”¾åŠŸèƒ½
            fullScreen: true,      // å¯ç”¨å…¨å±åŠŸèƒ½
            pager: false, //é¡µç ,
            zoomFromOrigin: true,   // ä»åŸå§‹ä½ç½®ç¼©æ”¾
            actualSize: true,       // å¯ç”¨æŸ¥çœ‹å®é™…å¤§å°çš„åŠŸèƒ½
            enableZoomAfter: 300,    // å»¶è¿Ÿç¼©æ”¾ï¼Œç¡®ä¿å›¾ç‰‡åŠ è½½å®Œæˆåå¯ç¼©æ”¾
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // ä¿®å¤é€‰æ‹©å™¨
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- å›åˆ°é¡¶éƒ¨çš„æŒ‰é’®-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- è¿”å›çš„æŒ‰é’®-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>
<script src="/js/emojiHandler.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    wrapEmojis('.paper');
  });
</script>