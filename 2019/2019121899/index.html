<!DOCTYPE html>
<html lang="zh-CN">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="CSRNet：Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes" />
    <meta name="hexo-theme-A4" content="v1.9.8" />
    <link rel="alternate icon" type="image/webp" href="/img/20250602032635.jpg">
    <title>Yann | 我愿做你光华中淡淡的一笔</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--注意：首页既不是post也不是page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--返回顶部css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--目录-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


   
        
<link rel="stylesheet" href="/css/custom.css">

    

<meta name="generator" content="Hexo 5.4.2"></head>
    
    

    
    



    

    
    




    
    <style>
        :root {
            --waline-theme-color: #323e74; 
            --waline-color: #323e74; 
            --waline-border-color: #323e74; 
            --waline-white: #323e74; 
            --waline-bgcolor-light: #f2fafc;  
        }
        body {
            color: #323e74;
            background: #eaeae8;
        }
        .post-md code {
            background: #e7f7f3;
            color: #7f688d; 
        }
        .post-md pre, .post-md .highlight {
            background: #e7f7f3;
            color: #7f688d; 
        }
        pre .string, pre .value, pre .inheritance, pre .header, pre .ruby .symbol, pre .xml .cdata {
            color: #323e74;
        }
        pre .number, pre .preprocessor, pre .built_in, pre .literal, pre .params, pre .constant {
            color: #323e74;
        }
        .year-font-color {
            color: #323e74 !important;
        }
        .wl-card span.wl-nick {
            color: #323e74; 
        }
        .wl-card .wl-badge {
            border: 1px solid #323e74;
            color: #323e74; 
        }
        .wl-btn {
            border: 1px solid #323e74; 
            color:  #323e74;  
        }
        .wl-btn.primary {
            color: #f2fafc; 
        }
        .wl-header label {
            color: #323e74;
        }
        a {
            color: #7f688d;
        }

        .post-md a {
            color: #7f688d;
        }

        .nav li a {
            color: #7f688d;
        }

        .archive-main a:link {
            color: #7f688d;
        }
        .archive-main a:visited {
            color: #767c7c; 
        }

        .archive li span {
            color: #323e74;
        }

        .post-main-title {
            color: #323e74;
        }

        .post-md h1,
        .post-md h2,
        .post-md h3,
        .post-md h4,
        .post-md h5,
        .post-md h6 {
            color: #323e74;
        }

        [data-waline] p {
            color: #323e74;
        }
        [data-waline] a {
            color: #323e74;
        } 
        .wl-sort li.active {
            color: #323e74;
        }

        .wl-card .wl-meta>span {
            background: #f2fafc;
        }

        .paper {
            background: #eaeae8;
        }

        .index-main {
            background: #f2fafc;
        }

        .paper-main {
            background: #f2fafc;
        }

        .wl-panel {
            background: #f2fafc;
        }

        .archive li:nth-child(odd) {
            background: #f2fafc;
            ;
        }

        .archive li:nth-child(even) {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(odd) td {
            background: #f2fafc;
        }

        .post-md table tr:nth-child(even) td {
            background: #f2fafc;
        }

    
        .progress-wrap::after {
            color: #323e74; /* 箭头的颜色 */
        }
        .progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* 边框的颜色 */
        }
        .progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* 鼠标滑过的箭头颜色 */
         }

        .return-to-last-progress-wrap::after {
            color: #323e74; /* 箭头的颜色 */
        }
        .return-to-last-progress-wrap svg.progress-circle path {
	        stroke: #323e74; /* 边框的颜色 */
        }
        .return-to-last-progress-wrap::before {
	        background-image: linear-gradient(298deg, #7f688d, #7f688d); /* 鼠标滑过的箭头颜色 */
         }

         .left-toc-container::-webkit-scrollbar-thumb {
            background-color: #323e74; /* 设置滚动条拖动块的颜色 */
        }

        .bs-docs-sidebar .nav>.active>a,
        .bs-docs-sidebar .nav>li>a:hover,
        .bs-docs-sidebar .nav>li>a:focus {
            color: #7f688d;
            border-left-color: #7f688d;
        }
        .bs-docs-sidebar .nav>li>a {
            color:  #323e74;
        }
    </style>

    
    <style>
        body {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* 背景固定，不随页面滚动 */
            background-repeat: no-repeat;  /* 防止背景图片重复 */
            background-size: cover;       /* 背景自适应大小，覆盖整个背景 */
            background-position: center;   /* 背景居中显示 */
        }
        .paper {
            background-image: url(/img/3.jpg);
            background-attachment: fixed;  /* 背景固定，不随页面滚动 */
            background-repeat: no-repeat;  /* 防止背景图片重复 */
            background-size: cover;       /* 背景自适应大小，覆盖整个背景 */
            background-position: center;   /* 背景居中显示 */
        }  
    </style>


    
    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        <script>
            const options = {
                bottom: '40px', // default: '32px'
                right: 'unset', // default: '32px'
                left: '42px', // default: 'unset'
                time: '0.3s', // default: '0.3s'
                mixColor: '#fff', // default: '#fff'
                backgroundColor: ' #eaeae8  ',  // default: '#fff'
                buttonColorDark: '#100f2c',  // default: '#100f2c'
                buttonColorLight: '#fff', // default: '#fff'
                saveInCookies: true, // default: true,
                label: '🌓', // default: ''
                autoMatchOsTheme: true // default: true
            }
            const darkmode = new Darkmode(options);
            darkmode.showWidget();
        </script>
        
        
            
                <div class="left-toc-container">
                    <nav id="toc" class="bs-docs-sidebar"></nav>
                </div>
            
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <style>
            .header-img {
                width: 56px;
                height: auto;
                object-fit: cover; /* 保持图片比例 */
                transition: transform 0.3s ease-in-out; 
                border-radius: 0; 
            }
            
        </style>
        <img 
            alt="^-^" 
            cache-control="max-age=86400" 
            class="header-img" 
            src="/img/20250602032635.jpg" 
        />
        <div class="header-content">
            <a class="logo" href="/">Yann</a> 
            <span class="description">人工智能、计算机、机器学习、linux、程序员</span> 
        </div>
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">文章</a></li>
            
        
            
                <li><a href="/about/">关于</a></li>
            
        
            
                <li><a href="/tags/">标签</a></li>
            
        
            
                <li><a href="/categories/">分类</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    CSRNet：Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>最近更新：2021-03-28</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>字数总计：3.5k</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>阅读估时：15分钟</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        阅读量：<span id="busuanzi_value_page_pv"></span>次
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#1%E3%80%81MCNN%E7%9A%84%E5%A4%9A%E5%88%97%E8%AE%BE%E8%AE%A1%E6%B2%A1%E6%9C%89%E6%98%BE%E8%91%97%E4%BD%9C%E7%94%A8%EF%BC%9A"><span class="post-toc-text">1、MCNN的多列设计没有显著作用：</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#2%E3%80%81%E8%86%A8%E8%83%80%E5%8D%B7%E7%A7%AF%E4%BC%98%E4%BA%8E%E5%8F%8D%E5%8D%B7%E7%A7%AF"><span class="post-toc-text">2、膨胀卷积优于反卷积</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%B4%A1%E7%8C%AE%EF%BC%9A"><span class="post-toc-text">贡献：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%B8%BB%E8%A6%81%E5%AE%9E%E7%8E%B0%EF%BC%9A"><span class="post-toc-text">主要实现：</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%9A"><span class="post-toc-text">网络结构：</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%EF%BC%9A"><span class="post-toc-text">数据增强：</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="post-toc-text">损失函数：</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#%E4%BB%A3%E7%A0%81%EF%BC%9Ahttps-github-com-leeyeehoo-CSRNet-pytorch"><span class="post-toc-text">代码：https:&#x2F;&#x2F;github.com&#x2F;leeyeehoo&#x2F;CSRNet-pytorch</span></a></li></ol></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#step1-install"><span class="post-toc-text">step1. install</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#step2-make-dataset-py"><span class="post-toc-text">step2.  make_dataset.py</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#step3-Training"><span class="post-toc-text">step3.  Training</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#step4-Testing"><span class="post-toc-text">step4. Testing</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Reading-paper-https-arxiv-org-pdf-1802-10062-pdf"><span class="post-toc-text">Reading paper   https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1802.10062.pdf</span></a>
            
        
        <div class=".article-gallery"><blockquote>
<p>主要观点：CSRnet网络模型主要分为前端和后端网络，采用剔除了全连接层的VGG-16作为CSRnet的前端网络，输出图像的大小为原始输入图像的1/8。卷积层的数量增加会导致输出的图像变小，从而增加生成密度图的难度。所以本文采用空洞卷积神经网络作为后端网络，在保持分辨率的同时扩大感知域， 生成高质量的人群分布密度图。</p>
</blockquote>
<span id="more"></span>  
<h5 id="1、MCNN的多列设计没有显著作用："><a href="#1、MCNN的多列设计没有显著作用：" class="headerlink" title="1、MCNN的多列设计没有显著作用："></a>1、MCNN的多列设计没有显著作用：</h5><p>​    以前的拥挤场景分析工作主要基于<code>multi-scale architectures</code>。它们在该领域取得了很高的性能，但是当网络变得更深时，它们使用的设计也带来了两个显着的缺点：大量的训练时间和无效的分支结构（例如，MCNN ）。我们设计了一个实验来证明MCNN与表1中更深入的常规网络相比表现不佳。</p>
<pre><code>如我们先前所知，MCNN的每列专用于某一级别的拥塞场景。但是，使用MCNN的有效性可能并不突出。我们在图2中展示了MCNN中三个独立列（代表大，中，小的感受野）所学习的特征，并用ShanghaiTech Part A [18]数据集进行评估。该图中的三条曲线与具有不同拥塞密度的50个测试案例共享非常相似的模式（估计的错误率），这意味着这种分支结构中的每个列学习几乎相同的特征。它违背了MCNN设计的初衷，用于学习每列的不同功能。
</code></pre><h5 id="2、膨胀卷积优于反卷积"><a href="#2、膨胀卷积优于反卷积" class="headerlink" title="2、膨胀卷积优于反卷积"></a>2、膨胀卷积优于反卷积</h5><p>​    已经在分割任务中证明了膨胀卷积层，其精度得到显着提高，并且它是池化层的良好替代方案。 尽管池化层（例如，最大和平均池化）被广泛用于维持不变性和控制过度拟合，但是它们还显着地降低了空间分辨率，这意味着丢失了特征映射的空间信息。 反卷积层可以减轻信息的丢失，但额外的复杂性和执行延迟可能并不适合所有情况。 膨胀卷积是一个更好的选择，它使用稀疏内核（如图3所示）来交替汇集和卷积层。 该字符在不增加参数数量或计算量的情况下扩大了感受野（例如，添加更多卷积层可以产生更大的感受野但引入更多操作）。<br>​     为了保持特征图的分辨率，与使用<code>卷积+池化+反卷积</code>的方案相比，<code>膨胀卷积</code>显示出明显的优点。我们在图4中选择一个例子用于说明。输入是人群的图像，并且它分别通过两种方法处理以产生具有相同大小的输出。在第一种方法中，输入由具有因子2的最大池化层进行下采样，然后将其传递到具有3X3 Sobel内核的卷积层。由于生成的特征映射仅是原始输入的1/2，因此需要通过解卷积层（双线性插值）<code>bilinear interpolation</code>对其进行上采样。在另一种方法中，我们尝试扩张卷积并使相同的3X3 Sobel内核适应具有因子= 2步幅的扩张内核。输出与输入共享相同的维度。最重要的是，扩张卷积的输出包含更详细的信息。</p>
<h3 id="贡献："><a href="#贡献：" class="headerlink" title="贡献："></a>贡献：</h3><p>​    在本文中，我们设计了一个更深入的网络，称为<code>CSR-Net</code>，用于计算人群和生成高质量的密度图。我们的模型使用<code>纯卷积层</code>作为主干，以灵活的分辨率支持输入图像。为了限制网络的复杂性，我们在所有层中使用<code>小尺寸</code>的卷积滤波器（如3x3）。我们将VGG-16 [21]的前10层作为前端和<code>膨胀卷积层</code>作为后端部署，以扩大感受域并提取更深的特征而不会丢失分辨率（因为不使用池化层）。</p>
<h3 id="主要实现："><a href="#主要实现：" class="headerlink" title="主要实现："></a>主要实现：</h3><h5 id="网络结构："><a href="#网络结构：" class="headerlink" title="网络结构："></a>网络结构：</h5><p>​    此前端网络的输出大小是原始输入大小的<code>1/8</code>。如果我们继续堆叠更多卷积层和池化层（VGG-16中的基本组件），输出大小将进一步缩小，并且很难生成高质量的密度映射。 我们尝试将膨胀卷积层作为后端来提取更深层的显着性信息以及维持输出分辨率。<br>​     我们在表3中提出了四种CSRNet网络配置，它们具有相同的前端结构但后端的扩展速率不同。 关于前端，我们采用VGG-16网络（全连接层除外）并仅使用3X3内核。 根据VGG的论文，当使用相同大小的感受野时，使用具有小内核的更多卷积层比使用具有更大内核的更少层更有效。<br>​     通过移除完全连接的层，我们尝试确定需要从VGG-16使用的层数。 最关键的部分是在准确性和资源开销（包括训练时间，内存消耗和参数数量）之间进行权衡。 实验表明，在保持前十层VGG-16 [21]只有3个池化层而不是五层时，可以实现最佳权衡，以抑制由池化操作引起的对输出精度的不利影响。 由于CSRNet的输出（密度图）较小（输入尺寸的1/8），我们选择因子为8的双线性插值进行缩放，并确保<code>输出与输入图像具有相同的分辨率</code>。 使用相同的大小，CSRNet生成的结果与使用<code>PSNR</code>（峰值信噪比）和<code>SSIM</code>（图像中的结构相似性）的基础事实结果相当。</p>
<h5 id="数据增强："><a href="#数据增强：" class="headerlink" title="数据增强："></a>数据增强：</h5><p>​    我们从不同位置的每个图像裁剪9个patches，原始图像的大小为1/4。 前四个patches包含四分之三的图像而没有重叠，而其他五个patches则从输入图像中随机裁剪。 之后，我们镜像patches，以便我们将训练集加倍。</p>
<h5 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h5><p>​    使用简单的方法将CSRNet作为端到端结构进行培训。 前10个卷积层由训练有素的VGG-16进行微调[21]。 对于其他层，初始值来自具有0.01标准偏差的高斯初始化。 随机梯度下降（SGD）在训练期间以1e-6的固定学习率应用。 此外，我们选择欧氏距离来测量地面实况与我们生成的估计密度图之间的差异，这与其他工作类似[19,18,4]。 </p>
<pre><code>我们还使用和来评估ShanghaiTech Part A数据集上输出密度图的质量。 为了计算和，我们遵循[5]给出的预处理，其中包括密度图调整大小（与原始输入相同的大小），对地面实况和预测密度图进行插值和归一化。     除了人群计数之外，我们在TRANCOS数据集[44]上设置了一个实验，用于车辆计数，以证明我们的方法的稳健性和一般化。 TRANCOS是一个公共交通数据集，包含由监控摄像机捕获的1244个不同拥挤交通场景的图像，其中包含46796个带注释的车辆。 此外，提供感兴趣区域（ROI）用于评估。 图像的视角不固定，图像是从非常不同的场景中收集的。 网格平均值平均绝对误差（GAME）[44]用于此测试中的估值。 GAME定义如下：
</code></pre><h5 id="代码：https-github-com-leeyeehoo-CSRNet-pytorch"><a href="#代码：https-github-com-leeyeehoo-CSRNet-pytorch" class="headerlink" title="代码：https://github.com/leeyeehoo/CSRNet-pytorch"></a>代码：<a target="_blank" rel="noopener" href="https://github.com/leeyeehoo/CSRNet-pytorch">https://github.com/leeyeehoo/CSRNet-pytorch</a></h5><p>我在根据作者的github（<a target="_blank" rel="noopener" href="https://github.com/leeyeehoo/CSRNet-pytorch）">https://github.com/leeyeehoo/CSRNet-pytorch）</a>, 构建环境时遇到了一些问题。我调试过，百度花了很长时间才解决。写这一章的目的是帮助大家学得更好，少走弯路。</p>
<hr>
<h2 id="step1-install"><a href="#step1-install" class="headerlink" title="step1. install"></a>step1. install</h2><p>For the specific installation process, you can refer to the author’s github. Here I simply show the command line of my operation.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda create -n CSRNet python=3.6</span><br><span class="line">source activate CSRNet</span><br><span class="line">unzip CSRNet-pytorch-master.zip</span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch torchvision</span><br><span class="line">pip install decorator cloudpickle&gt;=0.2.1 dask[array]&gt;=1.0.0 matplotlib&gt;=2.0.0 networkx&gt;=1.8 scipy&gt;=0.17.0 bleach python-dateutil&gt;=2.1 decorator</span><br><span class="line">unzip ShanghaiTech_Crowd_Counting_Dataset.zip</span><br><span class="line">jupyter nbconvert --to script make_dataset.ipynb  #Convert .ipynb file to .py file</span><br></pre></td></tr></table></figure>
<h2 id="step2-make-dataset-py"><a href="#step2-make-dataset-py" class="headerlink" title="step2.  make_dataset.py"></a>step2.  make_dataset.py</h2><p>I just run the command to convert the <strong>make_dataset.ipynb</strong> file to a <strong>make_dataset.py</strong> file.Now you need to modify the contents of the <strong>make_dataset.py</strong> file.</p>
<p>Find the location where <strong>root</strong> is, add <strong>def main()</strong> in the above line</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/enwoR46SIMsZv8l.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/enwoR46SIMsZv8l.png" alt=""></a></p>
<p>Add these two lines at the end of the <strong>make_dataset.py</strong>, adjust the format of the code</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/pKdG1rO62jefQv8.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/pKdG1rO62jefQv8.png" alt=""></a></p>
<p>There is an error in the author’s source code, you need to change the code</p>
<p>Replace <strong>pts = np.array(zip(np.nonzero(gt)[1], np.nonzero(gt)[0]))</strong> with <strong>pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))</strong> </p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/mgDRkCdfPTN1WOJ.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/mgDRkCdfPTN1WOJ.png" alt=""></a></p>
<p>Then run the <strong>make_dataset.py</strong> file</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/Pg6v4LujYbHOsxf.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/Pg6v4LujYbHOsxf.png" alt=""></a></p>
<hr>
<p><strong>The above is just a general summary, then we will run and visualize the line-by-line code.</strong></p>
<p>I will use this image as an example.</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/pdmkGTUvf6DZFwE.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/pdmkGTUvf6DZFwE.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># coding: utf-8</span><br><span class="line">import h5py</span><br><span class="line">import scipy.io as io</span><br><span class="line">import PIL.Image as Image</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">from scipy.ndimage.filters import gaussian_filter </span><br><span class="line">import scipy</span><br><span class="line">import json</span><br><span class="line">from matplotlib import cm as CM</span><br><span class="line">from image import *</span><br><span class="line">from model import CSRNet</span><br><span class="line">import torch</span><br><span class="line">img_path=&#x27;D:\\paper\\CSRNet\\CSRNet\\dataset\\Shanghai\\part_A_final\\train_data\\images\\IMG_21.jpg&#x27;</span><br><span class="line">mat=&#x27;D:\\paper\\CSRNet\\CSRNet\\dataset\\Shanghai\\part_A_final\\train_data\\ground_truth\\GT_IMG_21.mat&#x27;</span><br><span class="line">mat = io.loadmat(mat)</span><br><span class="line">img= plt.imread(img_path)</span><br><span class="line">k = np.zeros((img.shape[0],img.shape[1]))</span><br></pre></td></tr></table></figure>
<p>The following is the information of <strong>k</strong></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/tohJys8YT1OXNbd.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/tohJys8YT1OXNbd.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gt = mat[&quot;image_info&quot;][0,0][0,0][0]</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/CZNjq5xyzYuJ3Ic.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/CZNjq5xyzYuJ3Ic.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for i in range(0,len(gt)):</span><br><span class="line">    if int(gt[i][1])&lt;img.shape[0] and int(gt[i][0])&lt;img.shape[1]:</span><br><span class="line">        k[int(gt[i][1]),int(gt[i][0])]=1</span><br><span class="line">gt = k</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/KeWcb2EO5Dmjuka.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/KeWcb2EO5Dmjuka.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">density = np.zeros(gt.shape, dtype=np.float32)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/nhXEzgB2YT9iWFQ.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/nhXEzgB2YT9iWFQ.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gt_count = np.count_nonzero(gt)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/LdpFMxQURclJiau.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/LdpFMxQURclJiau.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/utpH7GJKLF2gN6B.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/utpH7GJKLF2gN6B.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leafsize = 2048</span><br><span class="line"># build kdtree</span><br><span class="line">tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/uYoVTODtg7EZq4N.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/uYoVTODtg7EZq4N.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distances, locations = tree.query(pts, k=4)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/uYoVTODtg7EZq4N.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/uYoVTODtg7EZq4N.png" alt=""></a></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/lhQVo4bW1sqXp5L.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/lhQVo4bW1sqXp5L.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print(&#x27;generate density...&#x27;)</span><br><span class="line">for i, pt in enumerate(pts):</span><br><span class="line">    pt2d = np.zeros(gt.shape, dtype=np.float32)</span><br><span class="line">    pt2d[pt[1],pt[0]] = 1.</span><br><span class="line">    if gt_count &gt; 1:</span><br><span class="line">        sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1</span><br><span class="line">    else:</span><br><span class="line">        sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point</span><br><span class="line">    density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode=&#x27;constant&#x27;)</span><br><span class="line">print(&#x27;done.&#x27;)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/9cj482YACKQGe7I.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/9cj482YACKQGe7I.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k = density</span><br><span class="line">with h5py.File(img_path.replace(&#x27;.jpg&#x27;,&#x27;.h5&#x27;).replace(&#x27;images&#x27;,&#x27;ground_truth&#x27;), &#x27;w&#x27;) as hf:</span><br><span class="line">        hf[&#x27;density&#x27;] = k</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/g6rPTmICwBUWJqR.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/g6rPTmICwBUWJqR.png" alt=""></a></p>
<p>So far, we have generated true values for the image.  At this point I will sort the above code as follows</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># coding: utf-8</span><br><span class="line">import h5py</span><br><span class="line">import scipy.io as io</span><br><span class="line">import PIL.Image as Image</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">from scipy.ndimage.filters import gaussian_filter </span><br><span class="line">import scipy</span><br><span class="line">import json</span><br><span class="line">from matplotlib import cm as CM</span><br><span class="line">from image import *</span><br><span class="line">from model import CSRNet</span><br><span class="line">import torch</span><br><span class="line">def gaussian_filter_density(gt):</span><br><span class="line">    print(gt.shape)</span><br><span class="line">    density = np.zeros(gt.shape, dtype=np.float32)</span><br><span class="line">    gt_count = np.count_nonzero(gt)</span><br><span class="line">    if gt_count == 0:</span><br><span class="line">        return density</span><br><span class="line"></span><br><span class="line">    # pts = np.array(zip(np.nonzero(gt)[1], np.nonzero(gt)[0]))</span><br><span class="line">    pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))</span><br><span class="line">    leafsize = 2048</span><br><span class="line">    # build kdtree</span><br><span class="line">    tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)</span><br><span class="line">    # query kdtree</span><br><span class="line">    distances, locations = tree.query(pts, k=4)</span><br><span class="line"></span><br><span class="line">    print(&#x27;generate density...&#x27;)</span><br><span class="line">    for i, pt in enumerate(pts):</span><br><span class="line">        pt2d = np.zeros(gt.shape, dtype=np.float32)</span><br><span class="line">        pt2d[pt[1],pt[0]] = 1.</span><br><span class="line">        if gt_count &gt; 1:</span><br><span class="line">            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1</span><br><span class="line">        else:</span><br><span class="line">            sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point</span><br><span class="line">        density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode=&#x27;constant&#x27;)</span><br><span class="line">    print(&#x27;done.&#x27;)</span><br><span class="line">    return density</span><br><span class="line">img_path=&#x27;D:\\paper\\CSRNet\\CSRNet\\dataset\\Shanghai\\part_A_final\\train_data\\images\\IMG_21.jpg&#x27;</span><br><span class="line">mat=&#x27;D:\\paper\\CSRNet\\CSRNet\\dataset\\Shanghai\\part_A_final\\train_data\\ground_truth\\GT_IMG_21.mat&#x27;</span><br><span class="line">img_paths = []</span><br><span class="line">img_paths.append(img_path)</span><br><span class="line">    for img_path in img_paths:</span><br><span class="line">        print(img_path)</span><br><span class="line">        mat = io.loadmat(mat)</span><br><span class="line">        img= plt.imread(img_path)        </span><br><span class="line">        k = np.zeros((img.shape[0],img.shape[1]))</span><br><span class="line">        gt = mat[&quot;image_info&quot;][0,0][0,0][0]</span><br><span class="line">        for i in range(0,len(gt)):</span><br><span class="line">            if int(gt[i][1])&lt;img.shape[0] and int(gt[i][0])&lt;img.shape[1]:</span><br><span class="line">                k[int(gt[i][1]),int(gt[i][0])]=1</span><br><span class="line">        k = gaussian_filter_density(k)        </span><br><span class="line">        with h5py.File(img_path.replace(&#x27;.jpg&#x27;,&#x27;.h5&#x27;).replace(&#x27;images&#x27;,&#x27;ground_truth&#x27;), &#x27;w&#x27;) as hf:</span><br><span class="line">                hf[&#x27;density&#x27;] = k</span><br></pre></td></tr></table></figure>
<hr>
<p>And….then, let’s plot the true values of the image:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gt_file = h5py.File(img_paths[0].replace(&#x27;.jpg&#x27;,&#x27;.h5&#x27;).replace(&#x27;images&#x27;,&#x27;ground_truth&#x27;),&#x27;r&#x27;)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/K8SWQbPzkq4ei6a.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/K8SWQbPzkq4ei6a.png" alt=""></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groundtruth = np.asarray(gt_file[&#x27;density&#x27;])</span><br></pre></td></tr></table></figure>
<p>plot the true values of the image</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(groundtruth,cmap=CM.jet)</span><br></pre></td></tr></table></figure>
<p>Calculate how many people are in this picture</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.sum(groundtruth)</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>Based on the same operation above, I generated true values for all images in the dataset. The following operations are performed on the gpu server.</strong></p>
<p>That is, run the command line <strong>python make_dataset.py</strong> on the server to get the true value of all the pictures.</p>
<h2 id="step3-Training"><a href="#step3-Training" class="headerlink" title="step3.  Training"></a>step3.  Training</h2><p><strong>Note</strong>: if you use the python3.x</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. In model.py, change the xrange in line 18 to range</span><br><span class="line">2. In model.py, change line 19 to: list(self.frontend.state_dict().items())[i][1].data[:] = list(mod.state_dict().items())[i][1].data[:]</span><br><span class="line">3. In image.py, change line 40 to: target = cv2.resize(target,(target.shape[1]//8,target.shape[0]//8),interpolation = cv2.INTER_CUBIC)*64</span><br></pre></td></tr></table></figure>
<ul>
<li>In  part_A_train.json:change the path of images</li>
<li>In  part_A_val.json: change the path of images</li>
</ul>
<p>run </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py part_A_train.json part_A_val.json 0 0</span><br></pre></td></tr></table></figure>
<h2 id="step4-Testing"><a href="#step4-Testing" class="headerlink" title="step4. Testing"></a>step4. Testing</h2><p>These are our test images. number：182</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter nbconvert --to script val.ipynb</span><br></pre></td></tr></table></figure>
<p>Finally, the performance of this model on invisible data is tested. We will use the val.py file to verify the results. Remember to change the path to pre-train weights and images.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python val.py</span><br></pre></td></tr></table></figure>
<p>The average absolute error value that can be obtained by running this val.py file code</p>
<p>total ：182</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/IboNJTvDgh8VOa9.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/IboNJTvDgh8VOa9.png" alt=""></a></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/aMECFyiT6e4LqS7.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/aMECFyiT6e4LqS7.png" alt=""></a></p>
<p>The average absolute error value obtained is 65.96636956602663, which is very good.</p>
<hr>
<p>Now let’s examine the predicted values on a single image:</p>
<p>run</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python test_single-image.py</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/WGPcwDxmfYCjBKQ.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/WGPcwDxmfYCjBKQ.png" alt=""></a><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/XmbDW9JzY65CBTV.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/XmbDW9JzY65CBTV.png" alt=""></a><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/kIjcnEDtfaFwLy7.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/kIjcnEDtfaFwLy7.png" alt=""></a></p>
<p>another one</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/1zHNh6qZI8iSmDT.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/1zHNh6qZI8iSmDT.png" alt=""></a><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/HkBcDnfxN7YuJSV.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/HkBcDnfxN7YuJSV.png" alt=""></a><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/UykOqSaWmBin1Dl.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/UykOqSaWmBin1Dl.png" alt=""></a></p>
<p>The effect is not too good，maybe the model is not trained enough，i guess。</p>
<hr>
<h2 id="Reading-paper-https-arxiv-org-pdf-1802-10062-pdf"><a href="#Reading-paper-https-arxiv-org-pdf-1802-10062-pdf" class="headerlink" title="Reading paper   https://arxiv.org/pdf/1802.10062.pdf"></a>Reading paper   <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.10062.pdf">https://arxiv.org/pdf/1802.10062.pdf</a></h2><p>先说数据集用的ShanghaiTech dataset，根据.jpg和.mat处理之后生成train_den文件夹下.csv文件和图片一一对应<a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/tjIKHS7Q29FC5rV.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/tjIKHS7Q29FC5rV.png" alt=""></a></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/tjIKHS7Q29FC5rV.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/tjIKHS7Q29FC5rV.png" alt=""></a></p>
<p>数据集扩充处理再补充一下：使用的是高斯模糊作用于图像中的每个人的头部。所有图像都被裁剪成9块，每块的大小是图像原始大小的1/4。</p>
<hr>
<p>空洞卷积也有的博客翻译成膨胀卷积、扩张卷积啥的，anyway，使用扩张卷积是在不增加参数的情况下扩大内核。因此，如果扩张率为1就是中间的图在整个图像上进行卷积。将膨胀率增加到2最右边图它可以替代pooling层</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/HCJvzeDprl64k7N.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/HCJvzeDprl64k7N.png" alt=""></a></p>
<p>接下来再说它的数学公式上怎么计算的，</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/7kcQDAUlC5Z8a36.png" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/7kcQDAUlC5Z8a36.png" alt=""></a></p>
<p>由上公式得到这个([k + (k-1)<em>(r-1)] </em> [k + (k-1)*(r-1)])</p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/4WRXklYKHSq2Cpe.png" title="1554628903758" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/4WRXklYKHSq2Cpe.png" alt="1554628903758"></a></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/P8GFQJHRwcnq3s1.png" title="1554628933425" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/P8GFQJHRwcnq3s1.png" alt="1554628933425"></a></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/uUj6KkXVzb1Moli.png" title="1554628946463" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/uUj6KkXVzb1Moli.png" alt="1554628946463"></a></p>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2020/06/14/xvocP3frquXzMKZ.png" title="1554628958176" class="gallery-item" style="box-shadow: none;"> <img src="https://i.loli.net/2020/06/14/xvocP3frquXzMKZ.png" alt="1554628958176"></a></p>
<p>这个过程是：首先预测出给定图像的密度图。如果没有人，像素值pixel value设为0。如果该像素对应于人，则将分配某个预定义值。所以图像中的人数就是总共有的像素值total pixel values </p>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2019-12-18</span>
            
                <span>该篇文章被 Yann</span>
            
            
             
                <span>归为分类:
                    
                    
                        <a href='/categories/%E7%AC%94%E8%AE%B0/'>
                            笔记
                        </a>
                    
                </span>
            
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                
                    <span>上一篇：<a href='/2019/2019122011/'>leetcode 483.最小好进制</a></span>
                

                
                    <span class="post-footer-pre-next-last-span-right">下一篇：<a href="/2019/20191213002/">Fast Online Object Tracking and Segmentation:A Unifying Approach</a>
                    </span>
                
            </div>
    
        
    

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            © 1949-2025 China 

            
                

            
        </span>
       
    
</div>



<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>🌊看过大海的人不会忘记海的广阔🌊</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--目录-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--回到顶部按钮-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // 启用插件
            thumbnail: true,          // 显示缩略图
            zoom: true,               // 启用缩放功
            rotate: true,             // 启用旋转功能能
            autoplay: true,        // 启用自动播放功能
            fullScreen: true,      // 启用全屏功能
            pager: false, //页码,
            zoomFromOrigin: true,   // 从原始位置缩放
            actualSize: true,       // 启用查看实际大小的功能
            enableZoomAfter: 300,    // 延迟缩放，确保图片加载完成后可缩放
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // 修复选择器
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- 回到顶部的按钮-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- 返回的按钮-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>
<script src="/js/emojiHandler.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    wrapEmojis('.paper');
  });
</script>